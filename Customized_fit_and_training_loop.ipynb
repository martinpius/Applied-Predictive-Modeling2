{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customized fit and training loop.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1K0HG1r1+nE1EsnupnEA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/Applied-Predictive-Modeling2/blob/master/Customized_fit_and_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqAI2aMHuxFt",
        "outputId": "72333524-59a3-448c-c99f-33a1bee1b5df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import tensorflow as tf\n",
        "  print(f\"You are on CoLaB with tensorflow version: {tf.__version__}\")\n",
        "except Exception as e:\n",
        "  print(f\"{type(e)}: {e}\\n...please load your drive.\")\n",
        "  COLAB = False\n",
        "def time_fmt(t:float = 123.8173)->float:\n",
        "  h = int(t / (60 * 60))\n",
        "  m = int(t % (60 * 60)/ 60)\n",
        "  s = int(t % 60)\n",
        "  return f\"{h}: {m:>02}: {s:>05.2f}\"\n",
        "print(f\"....time testing....time testing...\\n>>>time elapse: {time_fmt()}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "You are on CoLaB with tensorflow version: 2.4.1\n",
            "....time testing....time testing...\n",
            ">>>time elapse: 0: 02: 03.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdODgYw_wlo5"
      },
      "source": [
        "#In this notebook we are going to build MLP from scratch\n",
        "#We will write the customized fit function and training loop:"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGbN_7BMyM5o"
      },
      "source": [
        "import sys, os, time\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQljZVruyU9f"
      },
      "source": [
        "#We start by defining our relu activation function:"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH3hmwcqycaN"
      },
      "source": [
        "class MyReLu(tf.keras.layers.Layer):\n",
        "  def __init__(self,name = 'my_relu', *args, **kwargs):\n",
        "    super(MyReLu, self).__init__(name = name, *args, **kwargs)\n",
        "    \n",
        "  def myrelu(self, inputs_tensor):\n",
        "    return tf.math.maximum(0, inputs_tensor)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPQ_ByZOzieL"
      },
      "source": [
        "#Testing if it does what is intended to do\n",
        "relu_custom = MyReLu()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYyDYRog0PKD",
        "outputId": "085f1011-7420-4960-e01b-f08928ec0ab7"
      },
      "source": [
        "relu_custom.myrelu(tf.random.normal(shape = (2,2), mean = -10, stddev= -4))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[0., 0.],\n",
              "       [0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxB2ozL0V46"
      },
      "source": [
        "#We define the dense layer from scratch using the following class: "
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNgKBr2a0p1x"
      },
      "source": [
        "class DenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, *args, **kwargs):\n",
        "    super(DenseLayer, self).__init__(*args, **kwargs)\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, inputs_dim):\n",
        "    self.w = self.add_weight(shape = (inputs_dim[-1], self.units),\n",
        "                             trainable = True, initializer = 'random_normal',\n",
        "                             name = 'weights')\n",
        "    self.b = self.add_weight(shape = (self.units, ), trainable = True,\n",
        "                             initializer = 'zeros', name = 'bias')\n",
        "    \n",
        "  def call(self, inputs_tensor):\n",
        "    x = tf.matmul(inputs_tensor, self.w) + self.b\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoCRacwK_Yhx"
      },
      "source": [
        "#Define the model class: To build a simple multi-layers perceptron"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDVsZ_2e_kMZ"
      },
      "source": [
        "class MLP(tf.keras.models.Model):\n",
        "  def __init__(self,num_classes = 10, *args, **kwargs):\n",
        "    super(MLP, self).__init__(*args, **kwargs)\n",
        "    self.dense1 = DenseLayer(units = 128, name = 'dense_1')\n",
        "    self.dense2 = DenseLayer(units = 64, name = 'dense_2')\n",
        "    self.outputs = DenseLayer(units = 10, name = 'outputs')\n",
        "    self.act = MyReLu()\n",
        "\n",
        "  def call(self, inputs_tensor, training = False):\n",
        "    x = self.dense1(inputs_tensor, training = training)\n",
        "    x = self.act(x)\n",
        "    x = self.dense2(x, training = training)\n",
        "    x = self.act(x)\n",
        "    x = self.outputs(x, training = training)\n",
        "    return x"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUDMieeHGNg8"
      },
      "source": [
        "model = MLP()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig8Puvc1GToo"
      },
      "source": [
        "#The customized fit for our simple mlp model:"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RkWZDHOGjIH"
      },
      "source": [
        "class CustomFit(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super(CustomFit, self).__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def compile(self,optimizer,loss):\n",
        "    super(CustomFit,self).compile()\n",
        "    self.loss = loss\n",
        "    self.optimizer = optimizer\n",
        "\n",
        "  def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Caclulate predictions\n",
        "            y_pred = self.model(x, training=True)\n",
        "\n",
        "            # Loss\n",
        "            loss = self.loss(y, y_pred)\n",
        "\n",
        "        # Gradients\n",
        "        training_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, training_vars)\n",
        "\n",
        "        # Step with optimizer\n",
        "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
        "        acc_metric.update_state(y, y_pred)\n",
        "\n",
        "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    x, y = data\n",
        "    y_pred = self.model(x, training=False)\n",
        "    loss = self.loss(y, y_pred)\n",
        "    acc_metric.update_state(y, y_pred)\n",
        "    return {\"loss\": loss, \"accuracy\": acc_metric.result()}"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UibdgNY6MSpo"
      },
      "source": [
        "#Loading and preprocess the data from keras:\n",
        "def _get_data():\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  x_train, x_test = x_train.astype(np.float32)/255.0, x_test.astype(np.float32)/255.0\n",
        "  x_train, x_test = x_train.reshape(-1, 784), x_test.reshape(-1, 784)\n",
        "  #y_train, y_test = tf.keras.utils.to_categorical(y_train, num_classes = 10), tf.keras.utils.to_categorical(y_test, num_classes = 10)\n",
        "  return (x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkRZp3R_OY4X"
      },
      "source": [
        "x_train, y_train, x_test, y_test = _get_data()"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tml0HOkOixX",
        "outputId": "098a9ae8-d3bb-461f-e052-e575f9e7f937"
      },
      "source": [
        "print(f\"x_train_shape: {x_train.shape}, y_train_shape: {y_train.shape}\\nx_test_shape: {x_test.shape}, y_test_shape: {y_test.shape}\")"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train_shape: (60000, 784), y_train_shape: (60000,)\n",
            "x_test_shape: (10000, 784), y_test_shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Nj8Y4uO9p4"
      },
      "source": [
        "#We can now train our model using the above data as follows:"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQAobsTWPI5o",
        "outputId": "1fb2b5bc-5ae9-4668-ebbd-9aae7571d4f4"
      },
      "source": [
        "tic = time.time()\n",
        "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "\n",
        "training = CustomFit(model)\n",
        "training.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "training.fit(x_train, y_train, batch_size=64, epochs=2)\n",
        "training.evaluate(x_test, y_test, batch_size=64)\n",
        "toc = time.time()\n",
        "print(f\"\\nTotal time for traoning and evaluation without GPU: {time_fmt(toc - tic)}\")"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2612 - accuracy: 0.9267\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2577 - accuracy: 0.9277\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.9273\n",
            "\n",
            "Total time for traoning and evaluation without GPU: 0: 00: 04.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5X_KWRzdyGc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}