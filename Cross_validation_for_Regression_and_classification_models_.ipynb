{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross validation for Regression and classification models .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnAaI+LAhZPc/xEmBKFRmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/Applied-Predictive-Modeling2/blob/master/Cross_validation_for_Regression_and_classification_models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPwhXaerGgir",
        "outputId": "7a692b74-329f-47d7-969f-26bc15854e6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import tensorflow as tf\n",
        "  print(f\"You are on colab with tensorflow version: {tf.__version__}\")\n",
        "except Exception as e:\n",
        "  COLAB = False\n",
        "  print(f\"{type(e)}: {e}\\n...please load your drive...\")\n",
        "def time_fmt(x:float = 123.98002)->float:\n",
        "  h = int(x / (60 * 60))\n",
        "  m = int(x % (60 * 60)/ 60)\n",
        "  s = int(x % 60)\n",
        "  return f\"{h}: {m:>03}: {s:>05.2f}\"\n",
        "print(f\"...testing...testing...testing...\\ntime elapse:{time_fmt()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "You are on colab with tensorflow version: 2.4.1\n",
            "...testing...testing...testing...\n",
            "time elapse:0: 002: 03.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6vPRnXSKyIO"
      },
      "source": [
        "import time, os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "pd.set_option('max_rows', 8)\n",
        "pd.set_option('max_columns', 0)\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otQ6mwKRNBHb"
      },
      "source": [
        "data = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\", na_values = ['NA','?'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJY3iCukbrpq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "6wj5vI9mOxZZ",
        "outputId": "f439e62b-6526-474f-ca6b-f03ce29893bf"
      },
      "source": [
        "display(data.isna().value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "id     job    area   income  aspect  subscriptions  dist_healthy  save_rate  dist_unhealthy  age    pop_dense  retail_dense  crime  product\n",
              "False  False  False  False   False   False          False         False      False           False  False      False         False  False      1941\n",
              "                     True    False   False          False         False      False           False  False      False         False  False        59\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_kB9X_yPY1j"
      },
      "source": [
        "#Income has some missing values: replace with the median income:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OO7sU8oQm6J"
      },
      "source": [
        "data['income'] = data['income'].fillna(data['income'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83q591jVQxN1"
      },
      "source": [
        "#For classification lets choose product as the target: We would like to know how\n",
        "#individuals spends their income on average purchasing of various items:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "9NGrozV_RMgK",
        "outputId": "a4c6fe69-8b8e-4f72-ac2f-ce43ce671446"
      },
      "source": [
        "data.groupby('product').income.mean().plot(kind = 'bar', color = 'red')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3858f7c210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0DAZp3cRgjM"
      },
      "source": [
        "#Product preferance also depends on other factors like age, pop_density etc\n",
        "#Lets see how age may influence product preferance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "iLvoTwZvSF4O",
        "outputId": "827e3897-eb56-4b9b-8aee-934b0aa063e0"
      },
      "source": [
        "data.groupby('product').age.mean().plot(kind = 'bar', color = 'blue')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3858fd4a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59VQeaPTSQdA"
      },
      "source": [
        "#Also we would like to see how the trend goes with other variables like population density:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "EzdHFPlSSjgB",
        "outputId": "c12b019a-2e2f-418e-cb9f-2abc5ea8223c"
      },
      "source": [
        "data.groupby('product').pop_dense.mean().plot(kind = 'bar', color = 'green')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f385f04f950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "c39gwvoZS_ZT",
        "outputId": "d3273ee8-39d2-4761-c1d8-a5d9bfda1c04"
      },
      "source": [
        "#We may want to know how the locations may influence product preferances \n",
        "data.groupby('product').area.value_counts().plot(kind = 'bar', color = 'red')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f385aeee810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prDCBq6yTnf_"
      },
      "source": [
        "#From the above simple charts we may get general overview of the prediction power for the selected variables: Same\n",
        "#analysis may be done on the remaining variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23J4VIINUVr4"
      },
      "source": [
        "#Preparing the data for training our classification model:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xZ2P0wMagl1"
      },
      "source": [
        "#Get the target and Convert to a dummy variable:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTLQY09napbP"
      },
      "source": [
        "target = pd.get_dummies(data['product'], prefix = 'product')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-igW2qpaywe"
      },
      "source": [
        "data.drop(['id'],axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GrVbcwAbeiK"
      },
      "source": [
        "job_cat = pd.get_dummies(data['job'], prefix = 'job')\n",
        "#subscriptions_cat = pd.get_dummies(data['subscriptions'], prefix = 'sbscr')\n",
        "area_cat = pd.get_dummies(data['area'], prefix = 'area')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKtLATi4cNt4"
      },
      "source": [
        "data.drop(['area','job'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "2UJ2SNcScdzH",
        "outputId": "7ee3b89a-a363-46d7-8c1b-3b514188c4af"
      },
      "source": [
        "display(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income</th>\n",
              "      <th>aspect</th>\n",
              "      <th>subscriptions</th>\n",
              "      <th>dist_healthy</th>\n",
              "      <th>save_rate</th>\n",
              "      <th>dist_unhealthy</th>\n",
              "      <th>age</th>\n",
              "      <th>pop_dense</th>\n",
              "      <th>retail_dense</th>\n",
              "      <th>crime</th>\n",
              "      <th>product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50876.0</td>\n",
              "      <td>13.100000</td>\n",
              "      <td>1</td>\n",
              "      <td>9.017895</td>\n",
              "      <td>35</td>\n",
              "      <td>11.738935</td>\n",
              "      <td>49</td>\n",
              "      <td>0.885827</td>\n",
              "      <td>0.492126</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60369.0</td>\n",
              "      <td>18.625000</td>\n",
              "      <td>2</td>\n",
              "      <td>7.766643</td>\n",
              "      <td>59</td>\n",
              "      <td>6.805396</td>\n",
              "      <td>51</td>\n",
              "      <td>0.874016</td>\n",
              "      <td>0.342520</td>\n",
              "      <td>0.400809</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55126.0</td>\n",
              "      <td>34.766667</td>\n",
              "      <td>1</td>\n",
              "      <td>3.632069</td>\n",
              "      <td>6</td>\n",
              "      <td>13.671772</td>\n",
              "      <td>44</td>\n",
              "      <td>0.944882</td>\n",
              "      <td>0.724409</td>\n",
              "      <td>0.207723</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51690.0</td>\n",
              "      <td>15.808333</td>\n",
              "      <td>1</td>\n",
              "      <td>5.372942</td>\n",
              "      <td>16</td>\n",
              "      <td>4.333286</td>\n",
              "      <td>50</td>\n",
              "      <td>0.889764</td>\n",
              "      <td>0.444882</td>\n",
              "      <td>0.361216</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>26576.0</td>\n",
              "      <td>33.358333</td>\n",
              "      <td>2</td>\n",
              "      <td>3.632069</td>\n",
              "      <td>20</td>\n",
              "      <td>8.380497</td>\n",
              "      <td>38</td>\n",
              "      <td>0.944882</td>\n",
              "      <td>0.877953</td>\n",
              "      <td>0.063851</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>28595.0</td>\n",
              "      <td>39.425000</td>\n",
              "      <td>3</td>\n",
              "      <td>7.168218</td>\n",
              "      <td>99</td>\n",
              "      <td>4.626950</td>\n",
              "      <td>36</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.744094</td>\n",
              "      <td>0.098703</td>\n",
              "      <td>f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>67949.0</td>\n",
              "      <td>5.733333</td>\n",
              "      <td>0</td>\n",
              "      <td>8.936292</td>\n",
              "      <td>26</td>\n",
              "      <td>3.281439</td>\n",
              "      <td>46</td>\n",
              "      <td>0.909449</td>\n",
              "      <td>0.598425</td>\n",
              "      <td>0.117803</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>61467.0</td>\n",
              "      <td>16.891667</td>\n",
              "      <td>0</td>\n",
              "      <td>4.312097</td>\n",
              "      <td>8</td>\n",
              "      <td>9.405648</td>\n",
              "      <td>48</td>\n",
              "      <td>0.925197</td>\n",
              "      <td>0.539370</td>\n",
              "      <td>0.451973</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       income     aspect  subscriptions  ...  retail_dense     crime  product\n",
              "0     50876.0  13.100000              1  ...      0.492126  0.071100        b\n",
              "1     60369.0  18.625000              2  ...      0.342520  0.400809        c\n",
              "2     55126.0  34.766667              1  ...      0.724409  0.207723        b\n",
              "3     51690.0  15.808333              1  ...      0.444882  0.361216        b\n",
              "...       ...        ...            ...  ...           ...       ...      ...\n",
              "1996  26576.0  33.358333              2  ...      0.877953  0.063851        a\n",
              "1997  28595.0  39.425000              3  ...      0.744094  0.098703        f\n",
              "1998  67949.0   5.733333              0  ...      0.598425  0.117803        c\n",
              "1999  61467.0  16.891667              0  ...      0.539370  0.451973        c\n",
              "\n",
              "[2000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf4dcHAEdsuC"
      },
      "source": [
        "#We obtain the standard scores for the continous columns to ensure uniformity:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuR2TzYNeQkp"
      },
      "source": [
        "cols = data.drop('product', axis = 1).columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eKn38FBeZvC"
      },
      "source": [
        "for col in cols:\n",
        "  data[col] = zscore(data[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "b67f2HxUejIf",
        "outputId": "11fc0fe4-60c8-4df2-9f3b-6e11cc6d58f0"
      },
      "source": [
        "display(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income</th>\n",
              "      <th>aspect</th>\n",
              "      <th>subscriptions</th>\n",
              "      <th>dist_healthy</th>\n",
              "      <th>save_rate</th>\n",
              "      <th>dist_unhealthy</th>\n",
              "      <th>age</th>\n",
              "      <th>pop_dense</th>\n",
              "      <th>retail_dense</th>\n",
              "      <th>crime</th>\n",
              "      <th>product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.607550</td>\n",
              "      <td>-0.664918</td>\n",
              "      <td>-0.208449</td>\n",
              "      <td>-0.048411</td>\n",
              "      <td>-0.215764</td>\n",
              "      <td>-0.314089</td>\n",
              "      <td>0.854321</td>\n",
              "      <td>0.079279</td>\n",
              "      <td>-0.465765</td>\n",
              "      <td>-1.120315</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.338053</td>\n",
              "      <td>-0.207748</td>\n",
              "      <td>0.839031</td>\n",
              "      <td>-0.266765</td>\n",
              "      <td>0.196869</td>\n",
              "      <td>-0.915161</td>\n",
              "      <td>1.394432</td>\n",
              "      <td>-0.075010</td>\n",
              "      <td>-1.445372</td>\n",
              "      <td>0.682945</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.184205</td>\n",
              "      <td>1.127906</td>\n",
              "      <td>-0.208449</td>\n",
              "      <td>-0.988286</td>\n",
              "      <td>-0.714362</td>\n",
              "      <td>-0.078604</td>\n",
              "      <td>-0.495957</td>\n",
              "      <td>0.850727</td>\n",
              "      <td>1.055205</td>\n",
              "      <td>-0.373087</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.526467</td>\n",
              "      <td>-0.440815</td>\n",
              "      <td>-0.208449</td>\n",
              "      <td>-0.684488</td>\n",
              "      <td>-0.542432</td>\n",
              "      <td>-1.216347</td>\n",
              "      <td>1.124377</td>\n",
              "      <td>0.130709</td>\n",
              "      <td>-0.775115</td>\n",
              "      <td>0.466401</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>-3.028085</td>\n",
              "      <td>1.011372</td>\n",
              "      <td>0.839031</td>\n",
              "      <td>-0.988286</td>\n",
              "      <td>-0.473660</td>\n",
              "      <td>-0.723260</td>\n",
              "      <td>-2.116291</td>\n",
              "      <td>0.850727</td>\n",
              "      <td>2.060592</td>\n",
              "      <td>-1.159964</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>-2.826971</td>\n",
              "      <td>1.513363</td>\n",
              "      <td>1.886511</td>\n",
              "      <td>-0.371196</td>\n",
              "      <td>0.884591</td>\n",
              "      <td>-1.180569</td>\n",
              "      <td>-2.656402</td>\n",
              "      <td>-1.566477</td>\n",
              "      <td>1.184101</td>\n",
              "      <td>-0.969344</td>\n",
              "      <td>f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1.093101</td>\n",
              "      <td>-1.274478</td>\n",
              "      <td>-1.255928</td>\n",
              "      <td>-0.062651</td>\n",
              "      <td>-0.370502</td>\n",
              "      <td>-1.344498</td>\n",
              "      <td>0.044154</td>\n",
              "      <td>0.387858</td>\n",
              "      <td>0.230272</td>\n",
              "      <td>-0.864885</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0.447425</td>\n",
              "      <td>-0.351174</td>\n",
              "      <td>-1.255928</td>\n",
              "      <td>-0.869615</td>\n",
              "      <td>-0.679976</td>\n",
              "      <td>-0.598362</td>\n",
              "      <td>0.584265</td>\n",
              "      <td>0.593578</td>\n",
              "      <td>-0.156415</td>\n",
              "      <td>0.962774</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        income    aspect  subscriptions  ...  retail_dense     crime  product\n",
              "0    -0.607550 -0.664918      -0.208449  ...     -0.465765 -1.120315        b\n",
              "1     0.338053 -0.207748       0.839031  ...     -1.445372  0.682945        c\n",
              "2    -0.184205  1.127906      -0.208449  ...      1.055205 -0.373087        b\n",
              "3    -0.526467 -0.440815      -0.208449  ...     -0.775115  0.466401        b\n",
              "...        ...       ...            ...  ...           ...       ...      ...\n",
              "1996 -3.028085  1.011372       0.839031  ...      2.060592 -1.159964        a\n",
              "1997 -2.826971  1.513363       1.886511  ...      1.184101 -0.969344        f\n",
              "1998  1.093101 -1.274478      -1.255928  ...      0.230272 -0.864885        c\n",
              "1999  0.447425 -0.351174      -1.255928  ...     -0.156415  0.962774        c\n",
              "\n",
              "[2000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO8FKiH5elQM"
      },
      "source": [
        "#Combine all datasets "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDFe9X_Tesnv"
      },
      "source": [
        "data = pd.concat([data, area_cat, subscriptions_cat, job_cat], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBjvLcSfe5GD"
      },
      "source": [
        "x = data.drop('product', axis = 1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC6b9y26e7YS",
        "outputId": "3ee5d59c-f275-42fe-d358-f40de7729492"
      },
      "source": [
        "print(f\"x_shape: {x.shape}, target_shape: {target.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_shape: (2000, 53), target_shape: (2000, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "OGdNTbljxNUH",
        "outputId": "ee8cda45-c7e8-43fe-f116-7b6ce3cbb18a"
      },
      "source": [
        "display(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-0.60754957, -0.66491815, -0.20844851, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [ 0.33805295, -0.20774798,  0.83903145, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.18420492,  1.12790602, -0.20844851, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [-2.82697122,  1.51336322,  1.88651142, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 1.09310058, -1.27447836, -1.25592848, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.44742528, -0.35117392, -1.25592848, ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga7zqNu6fQ08"
      },
      "source": [
        "#Checking for class imbalance:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cahU90eKfftN"
      },
      "source": [
        "target = pd.get_dummies(data['product'], prefix = 'prod')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dvM5qn6uKfU"
      },
      "source": [
        "y = target.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "FKLBG8Z1foT7",
        "outputId": "aed9dcd4-9c11-4b2c-9298-e09baed4ab8f"
      },
      "source": [
        "target.value_counts().plot(kind = 'bar', color = 'red')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f385ae19550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7IBj316f-mZ"
      },
      "source": [
        "#We can see that the categories for the class variable isn't well balanced \n",
        "#So we can retain the data structure by performing stratified cross-validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5DnJCyNgXQs"
      },
      "source": [
        "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 112)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi5IaMjulCX4",
        "outputId": "a31f97cf-9a03-4997-f221-22673f5ffd13"
      },
      "source": [
        "y_oos = []\n",
        "pred_oos = []\n",
        "fold = 0\n",
        "for train, test in folds.split(x, data['product']):\n",
        "  fold+=1\n",
        "  print(f\"fold number: {fold}\")\n",
        "  x_train = x[train]\n",
        "  x_test = x[test]\n",
        "  y_train = y[train]\n",
        "  y_test = y[test]\n",
        "\n",
        "  model = tf.keras.models.Sequential(name = 'mlp_scv')\n",
        "  model.add(tf.keras.layers.Dense(units = 128, kernel_initializer = 'random_normal', activation ='relu', name = 'dense1'))\n",
        "  model.add(tf.keras.layers.Dense(units = 64, kernel_initializer = 'random_normal', activation ='relu', name = 'dense2'))\n",
        "  model.add(tf.keras.layers.Dense(units = target.shape[1], activation = 'softmax',name = 'outputs'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop')\n",
        "  model.fit(x_train, y_train, validation_data = (x_test, y_test), verbose = 2, epochs = 200)\n",
        "  preds = model.predict(x_test)\n",
        "  y_oos.append(y_test)\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  pred_oos.append(preds)\n",
        "  yc = np.argmax(y_test, axis = 1)\n",
        "  acc_score = accuracy_score(yc, preds)\n",
        "  print(f\"the accuracy at fold: {k} is: {acc_score:.4f}\")\n",
        "\n",
        "y_oos = np.concatenate(y_oos)\n",
        "pred_oos = np.concatenate(pred_oos)\n",
        "y_c = np.argmax(y_oos, axis = 1)\n",
        "acc_score_overall = accuracy_score(y_c, pred_oos)\n",
        "print(f\"overall accuracy {acc_score_overall:.4f}\")\n",
        "\n",
        "y_oos = pd.DataFrame(y_oos)\n",
        "pred_oos = pd.DataFrame(pred_oos)\n",
        "cv_dfm = pd.concat([y_oos, pred_oos])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number: 1\n",
            "Epoch 1/200\n",
            "50/50 - 1s - loss: 1.2231 - val_loss: 0.9592\n",
            "Epoch 2/200\n",
            "50/50 - 0s - loss: 0.8314 - val_loss: 0.8506\n",
            "Epoch 3/200\n",
            "50/50 - 0s - loss: 0.7509 - val_loss: 0.8341\n",
            "Epoch 4/200\n",
            "50/50 - 0s - loss: 0.7098 - val_loss: 0.8180\n",
            "Epoch 5/200\n",
            "50/50 - 0s - loss: 0.6808 - val_loss: 0.8110\n",
            "Epoch 6/200\n",
            "50/50 - 0s - loss: 0.6630 - val_loss: 0.8100\n",
            "Epoch 7/200\n",
            "50/50 - 0s - loss: 0.6442 - val_loss: 0.7999\n",
            "Epoch 8/200\n",
            "50/50 - 0s - loss: 0.6246 - val_loss: 0.7995\n",
            "Epoch 9/200\n",
            "50/50 - 0s - loss: 0.6142 - val_loss: 0.7857\n",
            "Epoch 10/200\n",
            "50/50 - 0s - loss: 0.6024 - val_loss: 0.7836\n",
            "Epoch 11/200\n",
            "50/50 - 0s - loss: 0.5886 - val_loss: 0.7673\n",
            "Epoch 12/200\n",
            "50/50 - 0s - loss: 0.5792 - val_loss: 0.7695\n",
            "Epoch 13/200\n",
            "50/50 - 0s - loss: 0.5736 - val_loss: 0.7694\n",
            "Epoch 14/200\n",
            "50/50 - 0s - loss: 0.5558 - val_loss: 0.7725\n",
            "Epoch 15/200\n",
            "50/50 - 0s - loss: 0.5515 - val_loss: 0.7855\n",
            "Epoch 16/200\n",
            "50/50 - 0s - loss: 0.5416 - val_loss: 0.7736\n",
            "Epoch 17/200\n",
            "50/50 - 0s - loss: 0.5332 - val_loss: 0.7704\n",
            "Epoch 18/200\n",
            "50/50 - 0s - loss: 0.5243 - val_loss: 0.7906\n",
            "Epoch 19/200\n",
            "50/50 - 0s - loss: 0.5174 - val_loss: 0.7800\n",
            "Epoch 20/200\n",
            "50/50 - 0s - loss: 0.5066 - val_loss: 0.7927\n",
            "Epoch 21/200\n",
            "50/50 - 0s - loss: 0.5001 - val_loss: 0.7774\n",
            "Epoch 22/200\n",
            "50/50 - 0s - loss: 0.4920 - val_loss: 0.7799\n",
            "Epoch 23/200\n",
            "50/50 - 0s - loss: 0.4806 - val_loss: 0.8087\n",
            "Epoch 24/200\n",
            "50/50 - 0s - loss: 0.4786 - val_loss: 0.7927\n",
            "Epoch 25/200\n",
            "50/50 - 0s - loss: 0.4723 - val_loss: 0.7929\n",
            "Epoch 26/200\n",
            "50/50 - 0s - loss: 0.4639 - val_loss: 0.8208\n",
            "Epoch 27/200\n",
            "50/50 - 0s - loss: 0.4608 - val_loss: 0.7863\n",
            "Epoch 28/200\n",
            "50/50 - 0s - loss: 0.4516 - val_loss: 0.8146\n",
            "Epoch 29/200\n",
            "50/50 - 0s - loss: 0.4449 - val_loss: 0.8182\n",
            "Epoch 30/200\n",
            "50/50 - 0s - loss: 0.4397 - val_loss: 0.8180\n",
            "Epoch 31/200\n",
            "50/50 - 0s - loss: 0.4364 - val_loss: 0.8089\n",
            "Epoch 32/200\n",
            "50/50 - 0s - loss: 0.4250 - val_loss: 0.8576\n",
            "Epoch 33/200\n",
            "50/50 - 0s - loss: 0.4188 - val_loss: 0.8525\n",
            "Epoch 34/200\n",
            "50/50 - 0s - loss: 0.4178 - val_loss: 0.8391\n",
            "Epoch 35/200\n",
            "50/50 - 0s - loss: 0.4122 - val_loss: 0.8396\n",
            "Epoch 36/200\n",
            "50/50 - 0s - loss: 0.4060 - val_loss: 0.8513\n",
            "Epoch 37/200\n",
            "50/50 - 0s - loss: 0.3974 - val_loss: 0.8403\n",
            "Epoch 38/200\n",
            "50/50 - 0s - loss: 0.3955 - val_loss: 0.8686\n",
            "Epoch 39/200\n",
            "50/50 - 0s - loss: 0.3899 - val_loss: 0.8654\n",
            "Epoch 40/200\n",
            "50/50 - 0s - loss: 0.3823 - val_loss: 0.8546\n",
            "Epoch 41/200\n",
            "50/50 - 0s - loss: 0.3781 - val_loss: 0.8544\n",
            "Epoch 42/200\n",
            "50/50 - 0s - loss: 0.3722 - val_loss: 0.8723\n",
            "Epoch 43/200\n",
            "50/50 - 0s - loss: 0.3650 - val_loss: 0.8849\n",
            "Epoch 44/200\n",
            "50/50 - 0s - loss: 0.3577 - val_loss: 0.9021\n",
            "Epoch 45/200\n",
            "50/50 - 0s - loss: 0.3637 - val_loss: 0.9034\n",
            "Epoch 46/200\n",
            "50/50 - 0s - loss: 0.3498 - val_loss: 0.9508\n",
            "Epoch 47/200\n",
            "50/50 - 0s - loss: 0.3494 - val_loss: 0.9356\n",
            "Epoch 48/200\n",
            "50/50 - 0s - loss: 0.3399 - val_loss: 0.9391\n",
            "Epoch 49/200\n",
            "50/50 - 0s - loss: 0.3337 - val_loss: 0.9395\n",
            "Epoch 50/200\n",
            "50/50 - 0s - loss: 0.3352 - val_loss: 0.9332\n",
            "Epoch 51/200\n",
            "50/50 - 0s - loss: 0.3256 - val_loss: 0.9715\n",
            "Epoch 52/200\n",
            "50/50 - 0s - loss: 0.3246 - val_loss: 0.9452\n",
            "Epoch 53/200\n",
            "50/50 - 0s - loss: 0.3206 - val_loss: 0.9817\n",
            "Epoch 54/200\n",
            "50/50 - 0s - loss: 0.3103 - val_loss: 0.9663\n",
            "Epoch 55/200\n",
            "50/50 - 0s - loss: 0.3102 - val_loss: 0.9942\n",
            "Epoch 56/200\n",
            "50/50 - 0s - loss: 0.3038 - val_loss: 0.9948\n",
            "Epoch 57/200\n",
            "50/50 - 0s - loss: 0.3007 - val_loss: 0.9718\n",
            "Epoch 58/200\n",
            "50/50 - 0s - loss: 0.2952 - val_loss: 0.9918\n",
            "Epoch 59/200\n",
            "50/50 - 0s - loss: 0.2914 - val_loss: 0.9970\n",
            "Epoch 60/200\n",
            "50/50 - 0s - loss: 0.2935 - val_loss: 1.0124\n",
            "Epoch 61/200\n",
            "50/50 - 0s - loss: 0.2814 - val_loss: 1.0044\n",
            "Epoch 62/200\n",
            "50/50 - 0s - loss: 0.2800 - val_loss: 1.0332\n",
            "Epoch 63/200\n",
            "50/50 - 0s - loss: 0.2822 - val_loss: 1.0296\n",
            "Epoch 64/200\n",
            "50/50 - 0s - loss: 0.2674 - val_loss: 1.0291\n",
            "Epoch 65/200\n",
            "50/50 - 0s - loss: 0.2697 - val_loss: 1.0532\n",
            "Epoch 66/200\n",
            "50/50 - 0s - loss: 0.2674 - val_loss: 1.0510\n",
            "Epoch 67/200\n",
            "50/50 - 0s - loss: 0.2605 - val_loss: 1.0760\n",
            "Epoch 68/200\n",
            "50/50 - 0s - loss: 0.2560 - val_loss: 1.0596\n",
            "Epoch 69/200\n",
            "50/50 - 0s - loss: 0.2552 - val_loss: 1.0833\n",
            "Epoch 70/200\n",
            "50/50 - 0s - loss: 0.2480 - val_loss: 1.0739\n",
            "Epoch 71/200\n",
            "50/50 - 0s - loss: 0.2455 - val_loss: 1.1116\n",
            "Epoch 72/200\n",
            "50/50 - 0s - loss: 0.2478 - val_loss: 1.1583\n",
            "Epoch 73/200\n",
            "50/50 - 0s - loss: 0.2434 - val_loss: 1.0911\n",
            "Epoch 74/200\n",
            "50/50 - 0s - loss: 0.2338 - val_loss: 1.1196\n",
            "Epoch 75/200\n",
            "50/50 - 0s - loss: 0.2366 - val_loss: 1.1311\n",
            "Epoch 76/200\n",
            "50/50 - 0s - loss: 0.2277 - val_loss: 1.1194\n",
            "Epoch 77/200\n",
            "50/50 - 0s - loss: 0.2241 - val_loss: 1.1665\n",
            "Epoch 78/200\n",
            "50/50 - 0s - loss: 0.2221 - val_loss: 1.1589\n",
            "Epoch 79/200\n",
            "50/50 - 0s - loss: 0.2186 - val_loss: 1.1785\n",
            "Epoch 80/200\n",
            "50/50 - 0s - loss: 0.2202 - val_loss: 1.1568\n",
            "Epoch 81/200\n",
            "50/50 - 0s - loss: 0.2148 - val_loss: 1.1822\n",
            "Epoch 82/200\n",
            "50/50 - 0s - loss: 0.2065 - val_loss: 1.2159\n",
            "Epoch 83/200\n",
            "50/50 - 0s - loss: 0.2084 - val_loss: 1.1907\n",
            "Epoch 84/200\n",
            "50/50 - 0s - loss: 0.2034 - val_loss: 1.2131\n",
            "Epoch 85/200\n",
            "50/50 - 0s - loss: 0.2087 - val_loss: 1.1966\n",
            "Epoch 86/200\n",
            "50/50 - 0s - loss: 0.2040 - val_loss: 1.2025\n",
            "Epoch 87/200\n",
            "50/50 - 0s - loss: 0.1979 - val_loss: 1.2572\n",
            "Epoch 88/200\n",
            "50/50 - 0s - loss: 0.1975 - val_loss: 1.2527\n",
            "Epoch 89/200\n",
            "50/50 - 0s - loss: 0.1944 - val_loss: 1.2650\n",
            "Epoch 90/200\n",
            "50/50 - 0s - loss: 0.1898 - val_loss: 1.2573\n",
            "Epoch 91/200\n",
            "50/50 - 0s - loss: 0.1907 - val_loss: 1.2748\n",
            "Epoch 92/200\n",
            "50/50 - 0s - loss: 0.1785 - val_loss: 1.2261\n",
            "Epoch 93/200\n",
            "50/50 - 0s - loss: 0.1844 - val_loss: 1.2507\n",
            "Epoch 94/200\n",
            "50/50 - 0s - loss: 0.1791 - val_loss: 1.2551\n",
            "Epoch 95/200\n",
            "50/50 - 0s - loss: 0.1783 - val_loss: 1.3551\n",
            "Epoch 96/200\n",
            "50/50 - 0s - loss: 0.1758 - val_loss: 1.3693\n",
            "Epoch 97/200\n",
            "50/50 - 0s - loss: 0.1739 - val_loss: 1.2827\n",
            "Epoch 98/200\n",
            "50/50 - 0s - loss: 0.1716 - val_loss: 1.3009\n",
            "Epoch 99/200\n",
            "50/50 - 0s - loss: 0.1708 - val_loss: 1.3219\n",
            "Epoch 100/200\n",
            "50/50 - 0s - loss: 0.1682 - val_loss: 1.3340\n",
            "Epoch 101/200\n",
            "50/50 - 0s - loss: 0.1619 - val_loss: 1.3594\n",
            "Epoch 102/200\n",
            "50/50 - 0s - loss: 0.1632 - val_loss: 1.3529\n",
            "Epoch 103/200\n",
            "50/50 - 0s - loss: 0.1568 - val_loss: 1.3200\n",
            "Epoch 104/200\n",
            "50/50 - 0s - loss: 0.1568 - val_loss: 1.4191\n",
            "Epoch 105/200\n",
            "50/50 - 0s - loss: 0.1533 - val_loss: 1.4068\n",
            "Epoch 106/200\n",
            "50/50 - 0s - loss: 0.1518 - val_loss: 1.4099\n",
            "Epoch 107/200\n",
            "50/50 - 0s - loss: 0.1488 - val_loss: 1.3660\n",
            "Epoch 108/200\n",
            "50/50 - 0s - loss: 0.1473 - val_loss: 1.4782\n",
            "Epoch 109/200\n",
            "50/50 - 0s - loss: 0.1533 - val_loss: 1.3916\n",
            "Epoch 110/200\n",
            "50/50 - 0s - loss: 0.1491 - val_loss: 1.3884\n",
            "Epoch 111/200\n",
            "50/50 - 0s - loss: 0.1513 - val_loss: 1.4849\n",
            "Epoch 112/200\n",
            "50/50 - 0s - loss: 0.1444 - val_loss: 1.4402\n",
            "Epoch 113/200\n",
            "50/50 - 0s - loss: 0.1392 - val_loss: 1.4483\n",
            "Epoch 114/200\n",
            "50/50 - 0s - loss: 0.1359 - val_loss: 1.4635\n",
            "Epoch 115/200\n",
            "50/50 - 0s - loss: 0.1408 - val_loss: 1.4556\n",
            "Epoch 116/200\n",
            "50/50 - 0s - loss: 0.1336 - val_loss: 1.4599\n",
            "Epoch 117/200\n",
            "50/50 - 0s - loss: 0.1367 - val_loss: 1.4945\n",
            "Epoch 118/200\n",
            "50/50 - 0s - loss: 0.1378 - val_loss: 1.4700\n",
            "Epoch 119/200\n",
            "50/50 - 0s - loss: 0.1295 - val_loss: 1.5138\n",
            "Epoch 120/200\n",
            "50/50 - 0s - loss: 0.1274 - val_loss: 1.5235\n",
            "Epoch 121/200\n",
            "50/50 - 0s - loss: 0.1283 - val_loss: 1.5351\n",
            "Epoch 122/200\n",
            "50/50 - 0s - loss: 0.1253 - val_loss: 1.5493\n",
            "Epoch 123/200\n",
            "50/50 - 0s - loss: 0.1344 - val_loss: 1.5134\n",
            "Epoch 124/200\n",
            "50/50 - 0s - loss: 0.1222 - val_loss: 1.5622\n",
            "Epoch 125/200\n",
            "50/50 - 0s - loss: 0.1217 - val_loss: 1.5767\n",
            "Epoch 126/200\n",
            "50/50 - 0s - loss: 0.1208 - val_loss: 1.5552\n",
            "Epoch 127/200\n",
            "50/50 - 0s - loss: 0.1194 - val_loss: 1.5688\n",
            "Epoch 128/200\n",
            "50/50 - 0s - loss: 0.1142 - val_loss: 1.6115\n",
            "Epoch 129/200\n",
            "50/50 - 0s - loss: 0.1163 - val_loss: 1.5627\n",
            "Epoch 130/200\n",
            "50/50 - 0s - loss: 0.1100 - val_loss: 1.5947\n",
            "Epoch 131/200\n",
            "50/50 - 0s - loss: 0.1092 - val_loss: 1.6039\n",
            "Epoch 132/200\n",
            "50/50 - 0s - loss: 0.1098 - val_loss: 1.6097\n",
            "Epoch 133/200\n",
            "50/50 - 0s - loss: 0.1079 - val_loss: 1.5954\n",
            "Epoch 134/200\n",
            "50/50 - 0s - loss: 0.1104 - val_loss: 1.6311\n",
            "Epoch 135/200\n",
            "50/50 - 0s - loss: 0.1034 - val_loss: 1.6446\n",
            "Epoch 136/200\n",
            "50/50 - 0s - loss: 0.1074 - val_loss: 1.7190\n",
            "Epoch 137/200\n",
            "50/50 - 0s - loss: 0.1045 - val_loss: 1.6870\n",
            "Epoch 138/200\n",
            "50/50 - 0s - loss: 0.1009 - val_loss: 1.6396\n",
            "Epoch 139/200\n",
            "50/50 - 0s - loss: 0.1034 - val_loss: 1.8023\n",
            "Epoch 140/200\n",
            "50/50 - 0s - loss: 0.1009 - val_loss: 1.7303\n",
            "Epoch 141/200\n",
            "50/50 - 0s - loss: 0.1016 - val_loss: 1.7274\n",
            "Epoch 142/200\n",
            "50/50 - 0s - loss: 0.0945 - val_loss: 1.7142\n",
            "Epoch 143/200\n",
            "50/50 - 0s - loss: 0.1001 - val_loss: 1.7010\n",
            "Epoch 144/200\n",
            "50/50 - 0s - loss: 0.0945 - val_loss: 1.7508\n",
            "Epoch 145/200\n",
            "50/50 - 0s - loss: 0.1034 - val_loss: 1.7224\n",
            "Epoch 146/200\n",
            "50/50 - 0s - loss: 0.0922 - val_loss: 1.7751\n",
            "Epoch 147/200\n",
            "50/50 - 0s - loss: 0.0902 - val_loss: 1.7459\n",
            "Epoch 148/200\n",
            "50/50 - 0s - loss: 0.0910 - val_loss: 1.7469\n",
            "Epoch 149/200\n",
            "50/50 - 0s - loss: 0.0899 - val_loss: 1.7746\n",
            "Epoch 150/200\n",
            "50/50 - 0s - loss: 0.0886 - val_loss: 1.8704\n",
            "Epoch 151/200\n",
            "50/50 - 0s - loss: 0.0925 - val_loss: 1.8816\n",
            "Epoch 152/200\n",
            "50/50 - 0s - loss: 0.0856 - val_loss: 1.8508\n",
            "Epoch 153/200\n",
            "50/50 - 0s - loss: 0.0800 - val_loss: 1.8782\n",
            "Epoch 154/200\n",
            "50/50 - 0s - loss: 0.0847 - val_loss: 1.8435\n",
            "Epoch 155/200\n",
            "50/50 - 0s - loss: 0.0881 - val_loss: 1.9004\n",
            "Epoch 156/200\n",
            "50/50 - 0s - loss: 0.0813 - val_loss: 1.8301\n",
            "Epoch 157/200\n",
            "50/50 - 0s - loss: 0.0860 - val_loss: 1.8875\n",
            "Epoch 158/200\n",
            "50/50 - 0s - loss: 0.0825 - val_loss: 1.8775\n",
            "Epoch 159/200\n",
            "50/50 - 0s - loss: 0.0762 - val_loss: 1.9034\n",
            "Epoch 160/200\n",
            "50/50 - 0s - loss: 0.0818 - val_loss: 2.0017\n",
            "Epoch 161/200\n",
            "50/50 - 0s - loss: 0.0807 - val_loss: 1.9780\n",
            "Epoch 162/200\n",
            "50/50 - 0s - loss: 0.0836 - val_loss: 1.9259\n",
            "Epoch 163/200\n",
            "50/50 - 0s - loss: 0.0711 - val_loss: 1.9586\n",
            "Epoch 164/200\n",
            "50/50 - 0s - loss: 0.0768 - val_loss: 1.9929\n",
            "Epoch 165/200\n",
            "50/50 - 0s - loss: 0.0778 - val_loss: 2.0103\n",
            "Epoch 166/200\n",
            "50/50 - 0s - loss: 0.0675 - val_loss: 2.0925\n",
            "Epoch 167/200\n",
            "50/50 - 0s - loss: 0.0768 - val_loss: 2.0366\n",
            "Epoch 168/200\n",
            "50/50 - 0s - loss: 0.0746 - val_loss: 1.9957\n",
            "Epoch 169/200\n",
            "50/50 - 0s - loss: 0.0713 - val_loss: 2.0286\n",
            "Epoch 170/200\n",
            "50/50 - 0s - loss: 0.0743 - val_loss: 2.0444\n",
            "Epoch 171/200\n",
            "50/50 - 0s - loss: 0.0740 - val_loss: 2.0204\n",
            "Epoch 172/200\n",
            "50/50 - 0s - loss: 0.0651 - val_loss: 2.0238\n",
            "Epoch 173/200\n",
            "50/50 - 0s - loss: 0.0670 - val_loss: 2.0264\n",
            "Epoch 174/200\n",
            "50/50 - 0s - loss: 0.0679 - val_loss: 2.1626\n",
            "Epoch 175/200\n",
            "50/50 - 0s - loss: 0.0712 - val_loss: 2.0895\n",
            "Epoch 176/200\n",
            "50/50 - 0s - loss: 0.0641 - val_loss: 2.0675\n",
            "Epoch 177/200\n",
            "50/50 - 0s - loss: 0.0671 - val_loss: 2.1653\n",
            "Epoch 178/200\n",
            "50/50 - 0s - loss: 0.0701 - val_loss: 2.1243\n",
            "Epoch 179/200\n",
            "50/50 - 0s - loss: 0.0601 - val_loss: 2.1505\n",
            "Epoch 180/200\n",
            "50/50 - 0s - loss: 0.0616 - val_loss: 2.2259\n",
            "Epoch 181/200\n",
            "50/50 - 0s - loss: 0.0694 - val_loss: 2.1375\n",
            "Epoch 182/200\n",
            "50/50 - 0s - loss: 0.0608 - val_loss: 2.1983\n",
            "Epoch 183/200\n",
            "50/50 - 0s - loss: 0.0572 - val_loss: 2.2080\n",
            "Epoch 184/200\n",
            "50/50 - 0s - loss: 0.0593 - val_loss: 2.1794\n",
            "Epoch 185/200\n",
            "50/50 - 0s - loss: 0.0568 - val_loss: 2.2098\n",
            "Epoch 186/200\n",
            "50/50 - 0s - loss: 0.0613 - val_loss: 2.2675\n",
            "Epoch 187/200\n",
            "50/50 - 0s - loss: 0.0554 - val_loss: 2.2627\n",
            "Epoch 188/200\n",
            "50/50 - 0s - loss: 0.0533 - val_loss: 2.2192\n",
            "Epoch 189/200\n",
            "50/50 - 0s - loss: 0.0590 - val_loss: 2.2705\n",
            "Epoch 190/200\n",
            "50/50 - 0s - loss: 0.0559 - val_loss: 2.2797\n",
            "Epoch 191/200\n",
            "50/50 - 0s - loss: 0.0564 - val_loss: 2.3074\n",
            "Epoch 192/200\n",
            "50/50 - 0s - loss: 0.0556 - val_loss: 2.3421\n",
            "Epoch 193/200\n",
            "50/50 - 0s - loss: 0.0507 - val_loss: 2.3016\n",
            "Epoch 194/200\n",
            "50/50 - 0s - loss: 0.0510 - val_loss: 2.3770\n",
            "Epoch 195/200\n",
            "50/50 - 0s - loss: 0.0456 - val_loss: 2.4843\n",
            "Epoch 196/200\n",
            "50/50 - 0s - loss: 0.0567 - val_loss: 2.3388\n",
            "Epoch 197/200\n",
            "50/50 - 0s - loss: 0.0538 - val_loss: 2.3557\n",
            "Epoch 198/200\n",
            "50/50 - 0s - loss: 0.0503 - val_loss: 2.3969\n",
            "Epoch 199/200\n",
            "50/50 - 0s - loss: 0.0467 - val_loss: 2.3948\n",
            "Epoch 200/200\n",
            "50/50 - 0s - loss: 0.0446 - val_loss: 2.3972\n",
            "the accuracy at fold: 2 is: 0.6675\n",
            "fold number: 2\n",
            "Epoch 1/200\n",
            "50/50 - 1s - loss: 1.2226 - val_loss: 0.9413\n",
            "Epoch 2/200\n",
            "50/50 - 0s - loss: 0.8435 - val_loss: 0.8244\n",
            "Epoch 3/200\n",
            "50/50 - 0s - loss: 0.7615 - val_loss: 0.7830\n",
            "Epoch 4/200\n",
            "50/50 - 0s - loss: 0.7238 - val_loss: 0.7740\n",
            "Epoch 5/200\n",
            "50/50 - 0s - loss: 0.6910 - val_loss: 0.7505\n",
            "Epoch 6/200\n",
            "50/50 - 0s - loss: 0.6663 - val_loss: 0.7397\n",
            "Epoch 7/200\n",
            "50/50 - 0s - loss: 0.6514 - val_loss: 0.7456\n",
            "Epoch 8/200\n",
            "50/50 - 0s - loss: 0.6343 - val_loss: 0.7304\n",
            "Epoch 9/200\n",
            "50/50 - 0s - loss: 0.6213 - val_loss: 0.7095\n",
            "Epoch 10/200\n",
            "50/50 - 0s - loss: 0.6083 - val_loss: 0.7091\n",
            "Epoch 11/200\n",
            "50/50 - 0s - loss: 0.6007 - val_loss: 0.7143\n",
            "Epoch 12/200\n",
            "50/50 - 0s - loss: 0.5903 - val_loss: 0.7077\n",
            "Epoch 13/200\n",
            "50/50 - 0s - loss: 0.5806 - val_loss: 0.7159\n",
            "Epoch 14/200\n",
            "50/50 - 0s - loss: 0.5686 - val_loss: 0.7243\n",
            "Epoch 15/200\n",
            "50/50 - 0s - loss: 0.5626 - val_loss: 0.7072\n",
            "Epoch 16/200\n",
            "50/50 - 0s - loss: 0.5517 - val_loss: 0.7058\n",
            "Epoch 17/200\n",
            "50/50 - 0s - loss: 0.5438 - val_loss: 0.7068\n",
            "Epoch 18/200\n",
            "50/50 - 0s - loss: 0.5356 - val_loss: 0.7202\n",
            "Epoch 19/200\n",
            "50/50 - 0s - loss: 0.5308 - val_loss: 0.6922\n",
            "Epoch 20/200\n",
            "50/50 - 0s - loss: 0.5218 - val_loss: 0.7029\n",
            "Epoch 21/200\n",
            "50/50 - 0s - loss: 0.5104 - val_loss: 0.7064\n",
            "Epoch 22/200\n",
            "50/50 - 0s - loss: 0.5085 - val_loss: 0.7134\n",
            "Epoch 23/200\n",
            "50/50 - 0s - loss: 0.5035 - val_loss: 0.7044\n",
            "Epoch 24/200\n",
            "50/50 - 0s - loss: 0.4905 - val_loss: 0.6928\n",
            "Epoch 25/200\n",
            "50/50 - 0s - loss: 0.4881 - val_loss: 0.6981\n",
            "Epoch 26/200\n",
            "50/50 - 0s - loss: 0.4773 - val_loss: 0.6880\n",
            "Epoch 27/200\n",
            "50/50 - 0s - loss: 0.4702 - val_loss: 0.7085\n",
            "Epoch 28/200\n",
            "50/50 - 0s - loss: 0.4660 - val_loss: 0.6937\n",
            "Epoch 29/200\n",
            "50/50 - 0s - loss: 0.4558 - val_loss: 0.7020\n",
            "Epoch 30/200\n",
            "50/50 - 0s - loss: 0.4513 - val_loss: 0.7067\n",
            "Epoch 31/200\n",
            "50/50 - 0s - loss: 0.4407 - val_loss: 0.7439\n",
            "Epoch 32/200\n",
            "50/50 - 0s - loss: 0.4355 - val_loss: 0.7085\n",
            "Epoch 33/200\n",
            "50/50 - 0s - loss: 0.4293 - val_loss: 0.7287\n",
            "Epoch 34/200\n",
            "50/50 - 0s - loss: 0.4291 - val_loss: 0.7142\n",
            "Epoch 35/200\n",
            "50/50 - 0s - loss: 0.4231 - val_loss: 0.7156\n",
            "Epoch 36/200\n",
            "50/50 - 0s - loss: 0.4180 - val_loss: 0.7235\n",
            "Epoch 37/200\n",
            "50/50 - 0s - loss: 0.4026 - val_loss: 0.7236\n",
            "Epoch 38/200\n",
            "50/50 - 0s - loss: 0.4079 - val_loss: 0.7138\n",
            "Epoch 39/200\n",
            "50/50 - 0s - loss: 0.3920 - val_loss: 0.7560\n",
            "Epoch 40/200\n",
            "50/50 - 0s - loss: 0.3929 - val_loss: 0.7550\n",
            "Epoch 41/200\n",
            "50/50 - 0s - loss: 0.3803 - val_loss: 0.7412\n",
            "Epoch 42/200\n",
            "50/50 - 0s - loss: 0.3811 - val_loss: 0.7302\n",
            "Epoch 43/200\n",
            "50/50 - 0s - loss: 0.3720 - val_loss: 0.7604\n",
            "Epoch 44/200\n",
            "50/50 - 0s - loss: 0.3682 - val_loss: 0.7353\n",
            "Epoch 45/200\n",
            "50/50 - 0s - loss: 0.3651 - val_loss: 0.7869\n",
            "Epoch 46/200\n",
            "50/50 - 0s - loss: 0.3616 - val_loss: 0.7511\n",
            "Epoch 47/200\n",
            "50/50 - 0s - loss: 0.3517 - val_loss: 0.7694\n",
            "Epoch 48/200\n",
            "50/50 - 0s - loss: 0.3532 - val_loss: 0.8021\n",
            "Epoch 49/200\n",
            "50/50 - 0s - loss: 0.3427 - val_loss: 0.7767\n",
            "Epoch 50/200\n",
            "50/50 - 0s - loss: 0.3388 - val_loss: 0.7938\n",
            "Epoch 51/200\n",
            "50/50 - 0s - loss: 0.3318 - val_loss: 0.8066\n",
            "Epoch 52/200\n",
            "50/50 - 0s - loss: 0.3326 - val_loss: 0.8579\n",
            "Epoch 53/200\n",
            "50/50 - 0s - loss: 0.3277 - val_loss: 0.8056\n",
            "Epoch 54/200\n",
            "50/50 - 0s - loss: 0.3199 - val_loss: 0.8193\n",
            "Epoch 55/200\n",
            "50/50 - 0s - loss: 0.3155 - val_loss: 0.8256\n",
            "Epoch 56/200\n",
            "50/50 - 0s - loss: 0.3120 - val_loss: 0.8192\n",
            "Epoch 57/200\n",
            "50/50 - 0s - loss: 0.3076 - val_loss: 0.8136\n",
            "Epoch 58/200\n",
            "50/50 - 0s - loss: 0.2983 - val_loss: 0.8650\n",
            "Epoch 59/200\n",
            "50/50 - 0s - loss: 0.2969 - val_loss: 0.8580\n",
            "Epoch 60/200\n",
            "50/50 - 0s - loss: 0.2955 - val_loss: 0.8274\n",
            "Epoch 61/200\n",
            "50/50 - 0s - loss: 0.2904 - val_loss: 0.8516\n",
            "Epoch 62/200\n",
            "50/50 - 0s - loss: 0.2850 - val_loss: 0.8500\n",
            "Epoch 63/200\n",
            "50/50 - 0s - loss: 0.2827 - val_loss: 0.8673\n",
            "Epoch 64/200\n",
            "50/50 - 0s - loss: 0.2826 - val_loss: 0.8767\n",
            "Epoch 65/200\n",
            "50/50 - 0s - loss: 0.2798 - val_loss: 0.8735\n",
            "Epoch 66/200\n",
            "50/50 - 0s - loss: 0.2646 - val_loss: 0.8992\n",
            "Epoch 67/200\n",
            "50/50 - 0s - loss: 0.2707 - val_loss: 0.9070\n",
            "Epoch 68/200\n",
            "50/50 - 0s - loss: 0.2637 - val_loss: 0.8801\n",
            "Epoch 69/200\n",
            "50/50 - 0s - loss: 0.2544 - val_loss: 0.9375\n",
            "Epoch 70/200\n",
            "50/50 - 0s - loss: 0.2539 - val_loss: 0.9208\n",
            "Epoch 71/200\n",
            "50/50 - 0s - loss: 0.2496 - val_loss: 0.9178\n",
            "Epoch 72/200\n",
            "50/50 - 0s - loss: 0.2484 - val_loss: 0.9582\n",
            "Epoch 73/200\n",
            "50/50 - 0s - loss: 0.2370 - val_loss: 0.9503\n",
            "Epoch 74/200\n",
            "50/50 - 0s - loss: 0.2380 - val_loss: 0.9161\n",
            "Epoch 75/200\n",
            "50/50 - 0s - loss: 0.2362 - val_loss: 0.9616\n",
            "Epoch 76/200\n",
            "50/50 - 0s - loss: 0.2284 - val_loss: 0.9518\n",
            "Epoch 77/200\n",
            "50/50 - 0s - loss: 0.2284 - val_loss: 0.9597\n",
            "Epoch 78/200\n",
            "50/50 - 0s - loss: 0.2221 - val_loss: 1.0098\n",
            "Epoch 79/200\n",
            "50/50 - 0s - loss: 0.2236 - val_loss: 1.0050\n",
            "Epoch 80/200\n",
            "50/50 - 0s - loss: 0.2161 - val_loss: 0.9950\n",
            "Epoch 81/200\n",
            "50/50 - 0s - loss: 0.2153 - val_loss: 0.9507\n",
            "Epoch 82/200\n",
            "50/50 - 0s - loss: 0.2135 - val_loss: 1.1138\n",
            "Epoch 83/200\n",
            "50/50 - 0s - loss: 0.2077 - val_loss: 1.0543\n",
            "Epoch 84/200\n",
            "50/50 - 0s - loss: 0.2037 - val_loss: 1.0465\n",
            "Epoch 85/200\n",
            "50/50 - 0s - loss: 0.1996 - val_loss: 1.0366\n",
            "Epoch 86/200\n",
            "50/50 - 0s - loss: 0.1988 - val_loss: 1.0152\n",
            "Epoch 87/200\n",
            "50/50 - 0s - loss: 0.1940 - val_loss: 1.0533\n",
            "Epoch 88/200\n",
            "50/50 - 0s - loss: 0.1896 - val_loss: 1.1387\n",
            "Epoch 89/200\n",
            "50/50 - 0s - loss: 0.1947 - val_loss: 1.0423\n",
            "Epoch 90/200\n",
            "50/50 - 0s - loss: 0.1862 - val_loss: 1.0617\n",
            "Epoch 91/200\n",
            "50/50 - 0s - loss: 0.1843 - val_loss: 1.1253\n",
            "Epoch 92/200\n",
            "50/50 - 0s - loss: 0.1847 - val_loss: 1.1271\n",
            "Epoch 93/200\n",
            "50/50 - 0s - loss: 0.1793 - val_loss: 1.0916\n",
            "Epoch 94/200\n",
            "50/50 - 0s - loss: 0.1801 - val_loss: 1.1282\n",
            "Epoch 95/200\n",
            "50/50 - 0s - loss: 0.1706 - val_loss: 1.1331\n",
            "Epoch 96/200\n",
            "50/50 - 0s - loss: 0.1617 - val_loss: 1.1735\n",
            "Epoch 97/200\n",
            "50/50 - 0s - loss: 0.1749 - val_loss: 1.1266\n",
            "Epoch 98/200\n",
            "50/50 - 0s - loss: 0.1679 - val_loss: 1.1652\n",
            "Epoch 99/200\n",
            "50/50 - 0s - loss: 0.1645 - val_loss: 1.1272\n",
            "Epoch 100/200\n",
            "50/50 - 0s - loss: 0.1564 - val_loss: 1.2343\n",
            "Epoch 101/200\n",
            "50/50 - 0s - loss: 0.1583 - val_loss: 1.1793\n",
            "Epoch 102/200\n",
            "50/50 - 0s - loss: 0.1525 - val_loss: 1.1491\n",
            "Epoch 103/200\n",
            "50/50 - 0s - loss: 0.1567 - val_loss: 1.1802\n",
            "Epoch 104/200\n",
            "50/50 - 0s - loss: 0.1595 - val_loss: 1.1451\n",
            "Epoch 105/200\n",
            "50/50 - 0s - loss: 0.1490 - val_loss: 1.1916\n",
            "Epoch 106/200\n",
            "50/50 - 0s - loss: 0.1442 - val_loss: 1.2461\n",
            "Epoch 107/200\n",
            "50/50 - 0s - loss: 0.1508 - val_loss: 1.2156\n",
            "Epoch 108/200\n",
            "50/50 - 0s - loss: 0.1413 - val_loss: 1.2476\n",
            "Epoch 109/200\n",
            "50/50 - 0s - loss: 0.1359 - val_loss: 1.2634\n",
            "Epoch 110/200\n",
            "50/50 - 0s - loss: 0.1316 - val_loss: 1.2530\n",
            "Epoch 111/200\n",
            "50/50 - 0s - loss: 0.1358 - val_loss: 1.2579\n",
            "Epoch 112/200\n",
            "50/50 - 0s - loss: 0.1332 - val_loss: 1.2647\n",
            "Epoch 113/200\n",
            "50/50 - 0s - loss: 0.1324 - val_loss: 1.2986\n",
            "Epoch 114/200\n",
            "50/50 - 0s - loss: 0.1283 - val_loss: 1.2654\n",
            "Epoch 115/200\n",
            "50/50 - 0s - loss: 0.1276 - val_loss: 1.2869\n",
            "Epoch 116/200\n",
            "50/50 - 0s - loss: 0.1260 - val_loss: 1.3144\n",
            "Epoch 117/200\n",
            "50/50 - 0s - loss: 0.1228 - val_loss: 1.2812\n",
            "Epoch 118/200\n",
            "50/50 - 0s - loss: 0.1190 - val_loss: 1.3098\n",
            "Epoch 119/200\n",
            "50/50 - 0s - loss: 0.1190 - val_loss: 1.3469\n",
            "Epoch 120/200\n",
            "50/50 - 0s - loss: 0.1145 - val_loss: 1.3290\n",
            "Epoch 121/200\n",
            "50/50 - 0s - loss: 0.1145 - val_loss: 1.3523\n",
            "Epoch 122/200\n",
            "50/50 - 0s - loss: 0.1115 - val_loss: 1.4178\n",
            "Epoch 123/200\n",
            "50/50 - 0s - loss: 0.1166 - val_loss: 1.3620\n",
            "Epoch 124/200\n",
            "50/50 - 0s - loss: 0.1066 - val_loss: 1.4019\n",
            "Epoch 125/200\n",
            "50/50 - 0s - loss: 0.1100 - val_loss: 1.3777\n",
            "Epoch 126/200\n",
            "50/50 - 0s - loss: 0.0994 - val_loss: 1.3842\n",
            "Epoch 127/200\n",
            "50/50 - 0s - loss: 0.1067 - val_loss: 1.3931\n",
            "Epoch 128/200\n",
            "50/50 - 0s - loss: 0.1044 - val_loss: 1.4534\n",
            "Epoch 129/200\n",
            "50/50 - 0s - loss: 0.1001 - val_loss: 1.4118\n",
            "Epoch 130/200\n",
            "50/50 - 0s - loss: 0.0993 - val_loss: 1.4245\n",
            "Epoch 131/200\n",
            "50/50 - 0s - loss: 0.1036 - val_loss: 1.4472\n",
            "Epoch 132/200\n",
            "50/50 - 0s - loss: 0.0944 - val_loss: 1.4678\n",
            "Epoch 133/200\n",
            "50/50 - 0s - loss: 0.1017 - val_loss: 1.4394\n",
            "Epoch 134/200\n",
            "50/50 - 0s - loss: 0.0905 - val_loss: 1.4802\n",
            "Epoch 135/200\n",
            "50/50 - 0s - loss: 0.0954 - val_loss: 1.5439\n",
            "Epoch 136/200\n",
            "50/50 - 0s - loss: 0.0904 - val_loss: 1.5294\n",
            "Epoch 137/200\n",
            "50/50 - 0s - loss: 0.0908 - val_loss: 1.5477\n",
            "Epoch 138/200\n",
            "50/50 - 0s - loss: 0.0880 - val_loss: 1.5660\n",
            "Epoch 139/200\n",
            "50/50 - 0s - loss: 0.0883 - val_loss: 1.5198\n",
            "Epoch 140/200\n",
            "50/50 - 0s - loss: 0.0890 - val_loss: 1.5360\n",
            "Epoch 141/200\n",
            "50/50 - 0s - loss: 0.0894 - val_loss: 1.5560\n",
            "Epoch 142/200\n",
            "50/50 - 0s - loss: 0.0794 - val_loss: 1.6077\n",
            "Epoch 143/200\n",
            "50/50 - 0s - loss: 0.0855 - val_loss: 1.5992\n",
            "Epoch 144/200\n",
            "50/50 - 0s - loss: 0.0766 - val_loss: 1.5477\n",
            "Epoch 145/200\n",
            "50/50 - 0s - loss: 0.0815 - val_loss: 1.5601\n",
            "Epoch 146/200\n",
            "50/50 - 0s - loss: 0.0761 - val_loss: 1.6048\n",
            "Epoch 147/200\n",
            "50/50 - 0s - loss: 0.0816 - val_loss: 1.5877\n",
            "Epoch 148/200\n",
            "50/50 - 0s - loss: 0.0697 - val_loss: 1.6031\n",
            "Epoch 149/200\n",
            "50/50 - 0s - loss: 0.0760 - val_loss: 1.7589\n",
            "Epoch 150/200\n",
            "50/50 - 0s - loss: 0.0769 - val_loss: 1.6889\n",
            "Epoch 151/200\n",
            "50/50 - 0s - loss: 0.0720 - val_loss: 1.7140\n",
            "Epoch 152/200\n",
            "50/50 - 0s - loss: 0.0692 - val_loss: 1.7645\n",
            "Epoch 153/200\n",
            "50/50 - 0s - loss: 0.0678 - val_loss: 1.6452\n",
            "Epoch 154/200\n",
            "50/50 - 0s - loss: 0.0712 - val_loss: 1.7028\n",
            "Epoch 155/200\n",
            "50/50 - 0s - loss: 0.0683 - val_loss: 1.7190\n",
            "Epoch 156/200\n",
            "50/50 - 0s - loss: 0.0698 - val_loss: 1.6790\n",
            "Epoch 157/200\n",
            "50/50 - 0s - loss: 0.0662 - val_loss: 1.6867\n",
            "Epoch 158/200\n",
            "50/50 - 0s - loss: 0.0662 - val_loss: 1.7173\n",
            "Epoch 159/200\n",
            "50/50 - 0s - loss: 0.0653 - val_loss: 1.8269\n",
            "Epoch 160/200\n",
            "50/50 - 0s - loss: 0.0637 - val_loss: 1.7462\n",
            "Epoch 161/200\n",
            "50/50 - 0s - loss: 0.0649 - val_loss: 1.7700\n",
            "Epoch 162/200\n",
            "50/50 - 0s - loss: 0.0559 - val_loss: 1.7536\n",
            "Epoch 163/200\n",
            "50/50 - 0s - loss: 0.0687 - val_loss: 1.7538\n",
            "Epoch 164/200\n",
            "50/50 - 0s - loss: 0.0558 - val_loss: 1.8131\n",
            "Epoch 165/200\n",
            "50/50 - 0s - loss: 0.0607 - val_loss: 1.8096\n",
            "Epoch 166/200\n",
            "50/50 - 0s - loss: 0.0582 - val_loss: 1.7958\n",
            "Epoch 167/200\n",
            "50/50 - 0s - loss: 0.0539 - val_loss: 1.9117\n",
            "Epoch 168/200\n",
            "50/50 - 0s - loss: 0.0650 - val_loss: 1.8181\n",
            "Epoch 169/200\n",
            "50/50 - 0s - loss: 0.0575 - val_loss: 1.8402\n",
            "Epoch 170/200\n",
            "50/50 - 0s - loss: 0.0586 - val_loss: 1.8285\n",
            "Epoch 171/200\n",
            "50/50 - 0s - loss: 0.0509 - val_loss: 1.8992\n",
            "Epoch 172/200\n",
            "50/50 - 0s - loss: 0.0539 - val_loss: 1.8804\n",
            "Epoch 173/200\n",
            "50/50 - 0s - loss: 0.0595 - val_loss: 1.9076\n",
            "Epoch 174/200\n",
            "50/50 - 0s - loss: 0.0511 - val_loss: 1.9486\n",
            "Epoch 175/200\n",
            "50/50 - 0s - loss: 0.0512 - val_loss: 1.9350\n",
            "Epoch 176/200\n",
            "50/50 - 0s - loss: 0.0501 - val_loss: 1.9803\n",
            "Epoch 177/200\n",
            "50/50 - 0s - loss: 0.0467 - val_loss: 1.9957\n",
            "Epoch 178/200\n",
            "50/50 - 0s - loss: 0.0509 - val_loss: 1.9356\n",
            "Epoch 179/200\n",
            "50/50 - 0s - loss: 0.0537 - val_loss: 1.9706\n",
            "Epoch 180/200\n",
            "50/50 - 0s - loss: 0.0501 - val_loss: 2.0118\n",
            "Epoch 181/200\n",
            "50/50 - 0s - loss: 0.0497 - val_loss: 2.0141\n",
            "Epoch 182/200\n",
            "50/50 - 0s - loss: 0.0524 - val_loss: 1.9924\n",
            "Epoch 183/200\n",
            "50/50 - 0s - loss: 0.0492 - val_loss: 2.0171\n",
            "Epoch 184/200\n",
            "50/50 - 0s - loss: 0.0536 - val_loss: 1.9951\n",
            "Epoch 185/200\n",
            "50/50 - 0s - loss: 0.0400 - val_loss: 2.0831\n",
            "Epoch 186/200\n",
            "50/50 - 0s - loss: 0.0489 - val_loss: 2.0463\n",
            "Epoch 187/200\n",
            "50/50 - 0s - loss: 0.0452 - val_loss: 2.1041\n",
            "Epoch 188/200\n",
            "50/50 - 0s - loss: 0.0451 - val_loss: 2.1314\n",
            "Epoch 189/200\n",
            "50/50 - 0s - loss: 0.0484 - val_loss: 2.0681\n",
            "Epoch 190/200\n",
            "50/50 - 0s - loss: 0.0390 - val_loss: 2.1053\n",
            "Epoch 191/200\n",
            "50/50 - 0s - loss: 0.0440 - val_loss: 2.1112\n",
            "Epoch 192/200\n",
            "50/50 - 0s - loss: 0.0352 - val_loss: 2.0893\n",
            "Epoch 193/200\n",
            "50/50 - 0s - loss: 0.0423 - val_loss: 2.1672\n",
            "Epoch 194/200\n",
            "50/50 - 0s - loss: 0.0400 - val_loss: 2.1397\n",
            "Epoch 195/200\n",
            "50/50 - 0s - loss: 0.0442 - val_loss: 2.1495\n",
            "Epoch 196/200\n",
            "50/50 - 0s - loss: 0.0350 - val_loss: 2.1875\n",
            "Epoch 197/200\n",
            "50/50 - 0s - loss: 0.0421 - val_loss: 2.1459\n",
            "Epoch 198/200\n",
            "50/50 - 0s - loss: 0.0402 - val_loss: 2.2045\n",
            "Epoch 199/200\n",
            "50/50 - 0s - loss: 0.0385 - val_loss: 2.2505\n",
            "Epoch 200/200\n",
            "50/50 - 0s - loss: 0.0321 - val_loss: 2.2276\n",
            "the accuracy at fold: 2 is: 0.6875\n",
            "fold number: 3\n",
            "Epoch 1/200\n",
            "50/50 - 1s - loss: 1.2250 - val_loss: 0.9433\n",
            "Epoch 2/200\n",
            "50/50 - 0s - loss: 0.8871 - val_loss: 0.7730\n",
            "Epoch 3/200\n",
            "50/50 - 0s - loss: 0.7887 - val_loss: 0.7173\n",
            "Epoch 4/200\n",
            "50/50 - 0s - loss: 0.7421 - val_loss: 0.7016\n",
            "Epoch 5/200\n",
            "50/50 - 0s - loss: 0.7120 - val_loss: 0.6688\n",
            "Epoch 6/200\n",
            "50/50 - 0s - loss: 0.6829 - val_loss: 0.6648\n",
            "Epoch 7/200\n",
            "50/50 - 0s - loss: 0.6628 - val_loss: 0.6702\n",
            "Epoch 8/200\n",
            "50/50 - 0s - loss: 0.6519 - val_loss: 0.6677\n",
            "Epoch 9/200\n",
            "50/50 - 0s - loss: 0.6349 - val_loss: 0.6406\n",
            "Epoch 10/200\n",
            "50/50 - 0s - loss: 0.6232 - val_loss: 0.6558\n",
            "Epoch 11/200\n",
            "50/50 - 0s - loss: 0.6090 - val_loss: 0.6555\n",
            "Epoch 12/200\n",
            "50/50 - 0s - loss: 0.5993 - val_loss: 0.6510\n",
            "Epoch 13/200\n",
            "50/50 - 0s - loss: 0.5874 - val_loss: 0.6421\n",
            "Epoch 14/200\n",
            "50/50 - 0s - loss: 0.5801 - val_loss: 0.6380\n",
            "Epoch 15/200\n",
            "50/50 - 0s - loss: 0.5660 - val_loss: 0.6319\n",
            "Epoch 16/200\n",
            "50/50 - 0s - loss: 0.5568 - val_loss: 0.6587\n",
            "Epoch 17/200\n",
            "50/50 - 0s - loss: 0.5472 - val_loss: 0.6325\n",
            "Epoch 18/200\n",
            "50/50 - 0s - loss: 0.5373 - val_loss: 0.6589\n",
            "Epoch 19/200\n",
            "50/50 - 0s - loss: 0.5303 - val_loss: 0.6467\n",
            "Epoch 20/200\n",
            "50/50 - 0s - loss: 0.5233 - val_loss: 0.6437\n",
            "Epoch 21/200\n",
            "50/50 - 0s - loss: 0.5146 - val_loss: 0.6488\n",
            "Epoch 22/200\n",
            "50/50 - 0s - loss: 0.5060 - val_loss: 0.6741\n",
            "Epoch 23/200\n",
            "50/50 - 0s - loss: 0.4991 - val_loss: 0.6599\n",
            "Epoch 24/200\n",
            "50/50 - 0s - loss: 0.4936 - val_loss: 0.6681\n",
            "Epoch 25/200\n",
            "50/50 - 0s - loss: 0.4833 - val_loss: 0.6532\n",
            "Epoch 26/200\n",
            "50/50 - 0s - loss: 0.4773 - val_loss: 0.6580\n",
            "Epoch 27/200\n",
            "50/50 - 0s - loss: 0.4720 - val_loss: 0.6455\n",
            "Epoch 28/200\n",
            "50/50 - 0s - loss: 0.4689 - val_loss: 0.6570\n",
            "Epoch 29/200\n",
            "50/50 - 0s - loss: 0.4618 - val_loss: 0.6704\n",
            "Epoch 30/200\n",
            "50/50 - 0s - loss: 0.4485 - val_loss: 0.6712\n",
            "Epoch 31/200\n",
            "50/50 - 0s - loss: 0.4461 - val_loss: 0.6990\n",
            "Epoch 32/200\n",
            "50/50 - 0s - loss: 0.4396 - val_loss: 0.6858\n",
            "Epoch 33/200\n",
            "50/50 - 0s - loss: 0.4390 - val_loss: 0.6734\n",
            "Epoch 34/200\n",
            "50/50 - 0s - loss: 0.4259 - val_loss: 0.6780\n",
            "Epoch 35/200\n",
            "50/50 - 0s - loss: 0.4258 - val_loss: 0.7163\n",
            "Epoch 36/200\n",
            "50/50 - 0s - loss: 0.4225 - val_loss: 0.6782\n",
            "Epoch 37/200\n",
            "50/50 - 0s - loss: 0.4121 - val_loss: 0.6817\n",
            "Epoch 38/200\n",
            "50/50 - 0s - loss: 0.4051 - val_loss: 0.6873\n",
            "Epoch 39/200\n",
            "50/50 - 0s - loss: 0.4024 - val_loss: 0.7014\n",
            "Epoch 40/200\n",
            "50/50 - 0s - loss: 0.3970 - val_loss: 0.7327\n",
            "Epoch 41/200\n",
            "50/50 - 0s - loss: 0.3910 - val_loss: 0.7092\n",
            "Epoch 42/200\n",
            "50/50 - 0s - loss: 0.3795 - val_loss: 0.7165\n",
            "Epoch 43/200\n",
            "50/50 - 0s - loss: 0.3779 - val_loss: 0.7291\n",
            "Epoch 44/200\n",
            "50/50 - 0s - loss: 0.3789 - val_loss: 0.7242\n",
            "Epoch 45/200\n",
            "50/50 - 0s - loss: 0.3691 - val_loss: 0.7391\n",
            "Epoch 46/200\n",
            "50/50 - 0s - loss: 0.3648 - val_loss: 0.7195\n",
            "Epoch 47/200\n",
            "50/50 - 0s - loss: 0.3639 - val_loss: 0.7474\n",
            "Epoch 48/200\n",
            "50/50 - 0s - loss: 0.3538 - val_loss: 0.7827\n",
            "Epoch 49/200\n",
            "50/50 - 0s - loss: 0.3512 - val_loss: 0.7449\n",
            "Epoch 50/200\n",
            "50/50 - 0s - loss: 0.3479 - val_loss: 0.7659\n",
            "Epoch 51/200\n",
            "50/50 - 0s - loss: 0.3443 - val_loss: 0.7388\n",
            "Epoch 52/200\n",
            "50/50 - 0s - loss: 0.3311 - val_loss: 0.7833\n",
            "Epoch 53/200\n",
            "50/50 - 0s - loss: 0.3276 - val_loss: 0.7746\n",
            "Epoch 54/200\n",
            "50/50 - 0s - loss: 0.3248 - val_loss: 0.7780\n",
            "Epoch 55/200\n",
            "50/50 - 0s - loss: 0.3237 - val_loss: 0.7698\n",
            "Epoch 56/200\n",
            "50/50 - 0s - loss: 0.3215 - val_loss: 0.7969\n",
            "Epoch 57/200\n",
            "50/50 - 0s - loss: 0.3084 - val_loss: 0.7745\n",
            "Epoch 58/200\n",
            "50/50 - 0s - loss: 0.3097 - val_loss: 0.8130\n",
            "Epoch 59/200\n",
            "50/50 - 0s - loss: 0.3081 - val_loss: 0.8404\n",
            "Epoch 60/200\n",
            "50/50 - 0s - loss: 0.3024 - val_loss: 0.8170\n",
            "Epoch 61/200\n",
            "50/50 - 0s - loss: 0.2955 - val_loss: 0.8078\n",
            "Epoch 62/200\n",
            "50/50 - 0s - loss: 0.2862 - val_loss: 0.8025\n",
            "Epoch 63/200\n",
            "50/50 - 0s - loss: 0.2890 - val_loss: 0.8221\n",
            "Epoch 64/200\n",
            "50/50 - 0s - loss: 0.2803 - val_loss: 0.8813\n",
            "Epoch 65/200\n",
            "50/50 - 0s - loss: 0.2778 - val_loss: 0.8515\n",
            "Epoch 66/200\n",
            "50/50 - 0s - loss: 0.2724 - val_loss: 0.8474\n",
            "Epoch 67/200\n",
            "50/50 - 0s - loss: 0.2632 - val_loss: 0.8722\n",
            "Epoch 68/200\n",
            "50/50 - 0s - loss: 0.2623 - val_loss: 0.9401\n",
            "Epoch 69/200\n",
            "50/50 - 0s - loss: 0.2725 - val_loss: 0.8715\n",
            "Epoch 70/200\n",
            "50/50 - 0s - loss: 0.2605 - val_loss: 0.8790\n",
            "Epoch 71/200\n",
            "50/50 - 0s - loss: 0.2611 - val_loss: 0.8390\n",
            "Epoch 72/200\n",
            "50/50 - 0s - loss: 0.2482 - val_loss: 0.9178\n",
            "Epoch 73/200\n",
            "50/50 - 0s - loss: 0.2475 - val_loss: 0.9061\n",
            "Epoch 74/200\n",
            "50/50 - 0s - loss: 0.2527 - val_loss: 0.8945\n",
            "Epoch 75/200\n",
            "50/50 - 0s - loss: 0.2423 - val_loss: 0.8877\n",
            "Epoch 76/200\n",
            "50/50 - 0s - loss: 0.2331 - val_loss: 0.9357\n",
            "Epoch 77/200\n",
            "50/50 - 0s - loss: 0.2375 - val_loss: 0.9347\n",
            "Epoch 78/200\n",
            "50/50 - 0s - loss: 0.2276 - val_loss: 0.9682\n",
            "Epoch 79/200\n",
            "50/50 - 0s - loss: 0.2243 - val_loss: 0.9365\n",
            "Epoch 80/200\n",
            "50/50 - 0s - loss: 0.2263 - val_loss: 0.9298\n",
            "Epoch 81/200\n",
            "50/50 - 0s - loss: 0.2131 - val_loss: 0.9633\n",
            "Epoch 82/200\n",
            "50/50 - 0s - loss: 0.2171 - val_loss: 0.9474\n",
            "Epoch 83/200\n",
            "50/50 - 0s - loss: 0.2176 - val_loss: 1.0066\n",
            "Epoch 84/200\n",
            "50/50 - 0s - loss: 0.2083 - val_loss: 0.9736\n",
            "Epoch 85/200\n",
            "50/50 - 0s - loss: 0.2035 - val_loss: 0.9989\n",
            "Epoch 86/200\n",
            "50/50 - 0s - loss: 0.2066 - val_loss: 1.0967\n",
            "Epoch 87/200\n",
            "50/50 - 0s - loss: 0.1979 - val_loss: 0.9947\n",
            "Epoch 88/200\n",
            "50/50 - 0s - loss: 0.2000 - val_loss: 1.0004\n",
            "Epoch 89/200\n",
            "50/50 - 0s - loss: 0.1954 - val_loss: 1.0307\n",
            "Epoch 90/200\n",
            "50/50 - 0s - loss: 0.1902 - val_loss: 1.0402\n",
            "Epoch 91/200\n",
            "50/50 - 0s - loss: 0.1920 - val_loss: 1.0385\n",
            "Epoch 92/200\n",
            "50/50 - 0s - loss: 0.1896 - val_loss: 1.0533\n",
            "Epoch 93/200\n",
            "50/50 - 0s - loss: 0.1883 - val_loss: 1.0476\n",
            "Epoch 94/200\n",
            "50/50 - 0s - loss: 0.1835 - val_loss: 1.0797\n",
            "Epoch 95/200\n",
            "50/50 - 0s - loss: 0.1859 - val_loss: 1.0938\n",
            "Epoch 96/200\n",
            "50/50 - 0s - loss: 0.1754 - val_loss: 1.0707\n",
            "Epoch 97/200\n",
            "50/50 - 0s - loss: 0.1708 - val_loss: 1.0614\n",
            "Epoch 98/200\n",
            "50/50 - 0s - loss: 0.1699 - val_loss: 1.1595\n",
            "Epoch 99/200\n",
            "50/50 - 0s - loss: 0.1789 - val_loss: 1.0979\n",
            "Epoch 100/200\n",
            "50/50 - 0s - loss: 0.1648 - val_loss: 1.1049\n",
            "Epoch 101/200\n",
            "50/50 - 0s - loss: 0.1711 - val_loss: 1.1235\n",
            "Epoch 102/200\n",
            "50/50 - 0s - loss: 0.1641 - val_loss: 1.1484\n",
            "Epoch 103/200\n",
            "50/50 - 0s - loss: 0.1688 - val_loss: 1.1775\n",
            "Epoch 104/200\n",
            "50/50 - 0s - loss: 0.1518 - val_loss: 1.1479\n",
            "Epoch 105/200\n",
            "50/50 - 0s - loss: 0.1569 - val_loss: 1.1522\n",
            "Epoch 106/200\n",
            "50/50 - 0s - loss: 0.1559 - val_loss: 1.1675\n",
            "Epoch 107/200\n",
            "50/50 - 0s - loss: 0.1555 - val_loss: 1.1841\n",
            "Epoch 108/200\n",
            "50/50 - 0s - loss: 0.1466 - val_loss: 1.2456\n",
            "Epoch 109/200\n",
            "50/50 - 0s - loss: 0.1513 - val_loss: 1.2131\n",
            "Epoch 110/200\n",
            "50/50 - 0s - loss: 0.1432 - val_loss: 1.1640\n",
            "Epoch 111/200\n",
            "50/50 - 0s - loss: 0.1474 - val_loss: 1.1875\n",
            "Epoch 112/200\n",
            "50/50 - 0s - loss: 0.1449 - val_loss: 1.1935\n",
            "Epoch 113/200\n",
            "50/50 - 0s - loss: 0.1399 - val_loss: 1.2005\n",
            "Epoch 114/200\n",
            "50/50 - 0s - loss: 0.1445 - val_loss: 1.2139\n",
            "Epoch 115/200\n",
            "50/50 - 0s - loss: 0.1387 - val_loss: 1.2299\n",
            "Epoch 116/200\n",
            "50/50 - 0s - loss: 0.1386 - val_loss: 1.2197\n",
            "Epoch 117/200\n",
            "50/50 - 0s - loss: 0.1315 - val_loss: 1.3383\n",
            "Epoch 118/200\n",
            "50/50 - 0s - loss: 0.1379 - val_loss: 1.2373\n",
            "Epoch 119/200\n",
            "50/50 - 0s - loss: 0.1251 - val_loss: 1.2497\n",
            "Epoch 120/200\n",
            "50/50 - 0s - loss: 0.1293 - val_loss: 1.2678\n",
            "Epoch 121/200\n",
            "50/50 - 0s - loss: 0.1298 - val_loss: 1.2657\n",
            "Epoch 122/200\n",
            "50/50 - 0s - loss: 0.1292 - val_loss: 1.2933\n",
            "Epoch 123/200\n",
            "50/50 - 0s - loss: 0.1221 - val_loss: 1.3278\n",
            "Epoch 124/200\n",
            "50/50 - 0s - loss: 0.1237 - val_loss: 1.3012\n",
            "Epoch 125/200\n",
            "50/50 - 0s - loss: 0.1238 - val_loss: 1.3131\n",
            "Epoch 126/200\n",
            "50/50 - 0s - loss: 0.1238 - val_loss: 1.3403\n",
            "Epoch 127/200\n",
            "50/50 - 0s - loss: 0.1098 - val_loss: 1.4134\n",
            "Epoch 128/200\n",
            "50/50 - 0s - loss: 0.1173 - val_loss: 1.3296\n",
            "Epoch 129/200\n",
            "50/50 - 0s - loss: 0.1137 - val_loss: 1.4167\n",
            "Epoch 130/200\n",
            "50/50 - 0s - loss: 0.1198 - val_loss: 1.3903\n",
            "Epoch 131/200\n",
            "50/50 - 0s - loss: 0.1023 - val_loss: 1.3804\n",
            "Epoch 132/200\n",
            "50/50 - 0s - loss: 0.1153 - val_loss: 1.3735\n",
            "Epoch 133/200\n",
            "50/50 - 0s - loss: 0.1142 - val_loss: 1.4479\n",
            "Epoch 134/200\n",
            "50/50 - 0s - loss: 0.1056 - val_loss: 1.3794\n",
            "Epoch 135/200\n",
            "50/50 - 0s - loss: 0.1111 - val_loss: 1.4435\n",
            "Epoch 136/200\n",
            "50/50 - 0s - loss: 0.1049 - val_loss: 1.4514\n",
            "Epoch 137/200\n",
            "50/50 - 0s - loss: 0.1067 - val_loss: 1.3838\n",
            "Epoch 138/200\n",
            "50/50 - 0s - loss: 0.1071 - val_loss: 1.4858\n",
            "Epoch 139/200\n",
            "50/50 - 0s - loss: 0.1007 - val_loss: 1.4385\n",
            "Epoch 140/200\n",
            "50/50 - 0s - loss: 0.1022 - val_loss: 1.4358\n",
            "Epoch 141/200\n",
            "50/50 - 0s - loss: 0.1073 - val_loss: 1.4296\n",
            "Epoch 142/200\n",
            "50/50 - 0s - loss: 0.0999 - val_loss: 1.5241\n",
            "Epoch 143/200\n",
            "50/50 - 0s - loss: 0.1019 - val_loss: 1.5028\n",
            "Epoch 144/200\n",
            "50/50 - 0s - loss: 0.0942 - val_loss: 1.5967\n",
            "Epoch 145/200\n",
            "50/50 - 0s - loss: 0.1024 - val_loss: 1.5137\n",
            "Epoch 146/200\n",
            "50/50 - 0s - loss: 0.0944 - val_loss: 1.6329\n",
            "Epoch 147/200\n",
            "50/50 - 0s - loss: 0.0920 - val_loss: 1.5492\n",
            "Epoch 148/200\n",
            "50/50 - 0s - loss: 0.0956 - val_loss: 1.5660\n",
            "Epoch 149/200\n",
            "50/50 - 0s - loss: 0.0967 - val_loss: 1.5600\n",
            "Epoch 150/200\n",
            "50/50 - 0s - loss: 0.0909 - val_loss: 1.5788\n",
            "Epoch 151/200\n",
            "50/50 - 0s - loss: 0.0898 - val_loss: 1.5444\n",
            "Epoch 152/200\n",
            "50/50 - 0s - loss: 0.0966 - val_loss: 1.5245\n",
            "Epoch 153/200\n",
            "50/50 - 0s - loss: 0.0829 - val_loss: 1.5866\n",
            "Epoch 154/200\n",
            "50/50 - 0s - loss: 0.0831 - val_loss: 1.6008\n",
            "Epoch 155/200\n",
            "50/50 - 0s - loss: 0.0929 - val_loss: 1.5947\n",
            "Epoch 156/200\n",
            "50/50 - 0s - loss: 0.0845 - val_loss: 1.5743\n",
            "Epoch 157/200\n",
            "50/50 - 0s - loss: 0.0917 - val_loss: 1.6069\n",
            "Epoch 158/200\n",
            "50/50 - 0s - loss: 0.0761 - val_loss: 1.6091\n",
            "Epoch 159/200\n",
            "50/50 - 0s - loss: 0.0885 - val_loss: 1.5832\n",
            "Epoch 160/200\n",
            "50/50 - 0s - loss: 0.0880 - val_loss: 1.5900\n",
            "Epoch 161/200\n",
            "50/50 - 0s - loss: 0.0800 - val_loss: 1.7239\n",
            "Epoch 162/200\n",
            "50/50 - 0s - loss: 0.0876 - val_loss: 1.6252\n",
            "Epoch 163/200\n",
            "50/50 - 0s - loss: 0.0829 - val_loss: 1.6492\n",
            "Epoch 164/200\n",
            "50/50 - 0s - loss: 0.0786 - val_loss: 1.6530\n",
            "Epoch 165/200\n",
            "50/50 - 0s - loss: 0.0819 - val_loss: 1.6586\n",
            "Epoch 166/200\n",
            "50/50 - 0s - loss: 0.0781 - val_loss: 1.7096\n",
            "Epoch 167/200\n",
            "50/50 - 0s - loss: 0.0765 - val_loss: 1.7199\n",
            "Epoch 168/200\n",
            "50/50 - 0s - loss: 0.0746 - val_loss: 1.6886\n",
            "Epoch 169/200\n",
            "50/50 - 0s - loss: 0.0763 - val_loss: 1.6953\n",
            "Epoch 170/200\n",
            "50/50 - 0s - loss: 0.0699 - val_loss: 1.7516\n",
            "Epoch 171/200\n",
            "50/50 - 0s - loss: 0.0744 - val_loss: 1.7381\n",
            "Epoch 172/200\n",
            "50/50 - 0s - loss: 0.0704 - val_loss: 1.7176\n",
            "Epoch 173/200\n",
            "50/50 - 0s - loss: 0.0788 - val_loss: 1.7256\n",
            "Epoch 174/200\n",
            "50/50 - 0s - loss: 0.0686 - val_loss: 1.7875\n",
            "Epoch 175/200\n",
            "50/50 - 0s - loss: 0.0709 - val_loss: 1.7566\n",
            "Epoch 176/200\n",
            "50/50 - 0s - loss: 0.0661 - val_loss: 1.9116\n",
            "Epoch 177/200\n",
            "50/50 - 0s - loss: 0.0723 - val_loss: 1.7837\n",
            "Epoch 178/200\n",
            "50/50 - 0s - loss: 0.0671 - val_loss: 1.7656\n",
            "Epoch 179/200\n",
            "50/50 - 0s - loss: 0.0802 - val_loss: 1.7490\n",
            "Epoch 180/200\n",
            "50/50 - 0s - loss: 0.0641 - val_loss: 1.8255\n",
            "Epoch 181/200\n",
            "50/50 - 0s - loss: 0.0690 - val_loss: 1.7768\n",
            "Epoch 182/200\n",
            "50/50 - 0s - loss: 0.0688 - val_loss: 1.8225\n",
            "Epoch 183/200\n",
            "50/50 - 0s - loss: 0.0639 - val_loss: 1.8345\n",
            "Epoch 184/200\n",
            "50/50 - 0s - loss: 0.0566 - val_loss: 1.8852\n",
            "Epoch 185/200\n",
            "50/50 - 0s - loss: 0.0657 - val_loss: 1.8762\n",
            "Epoch 186/200\n",
            "50/50 - 0s - loss: 0.0626 - val_loss: 1.8254\n",
            "Epoch 187/200\n",
            "50/50 - 0s - loss: 0.0595 - val_loss: 1.9099\n",
            "Epoch 188/200\n",
            "50/50 - 0s - loss: 0.0606 - val_loss: 1.8088\n",
            "Epoch 189/200\n",
            "50/50 - 0s - loss: 0.0589 - val_loss: 1.9068\n",
            "Epoch 190/200\n",
            "50/50 - 0s - loss: 0.0546 - val_loss: 1.8708\n",
            "Epoch 191/200\n",
            "50/50 - 0s - loss: 0.0584 - val_loss: 1.9194\n",
            "Epoch 192/200\n",
            "50/50 - 0s - loss: 0.0583 - val_loss: 2.0257\n",
            "Epoch 193/200\n",
            "50/50 - 0s - loss: 0.0585 - val_loss: 1.8980\n",
            "Epoch 194/200\n",
            "50/50 - 0s - loss: 0.0536 - val_loss: 1.9480\n",
            "Epoch 195/200\n",
            "50/50 - 0s - loss: 0.0569 - val_loss: 1.8738\n",
            "Epoch 196/200\n",
            "50/50 - 0s - loss: 0.0566 - val_loss: 1.9255\n",
            "Epoch 197/200\n",
            "50/50 - 0s - loss: 0.0560 - val_loss: 1.9613\n",
            "Epoch 198/200\n",
            "50/50 - 0s - loss: 0.0562 - val_loss: 1.9393\n",
            "Epoch 199/200\n",
            "50/50 - 0s - loss: 0.0567 - val_loss: 1.9884\n",
            "Epoch 200/200\n",
            "50/50 - 0s - loss: 0.0555 - val_loss: 1.9960\n",
            "the accuracy at fold: 2 is: 0.7025\n",
            "fold number: 4\n",
            "Epoch 1/200\n",
            "50/50 - 1s - loss: 1.2646 - val_loss: 0.9515\n",
            "Epoch 2/200\n",
            "50/50 - 0s - loss: 0.8612 - val_loss: 0.8235\n",
            "Epoch 3/200\n",
            "50/50 - 0s - loss: 0.7759 - val_loss: 0.7704\n",
            "Epoch 4/200\n",
            "50/50 - 0s - loss: 0.7371 - val_loss: 0.7611\n",
            "Epoch 5/200\n",
            "50/50 - 0s - loss: 0.7060 - val_loss: 0.7059\n",
            "Epoch 6/200\n",
            "50/50 - 0s - loss: 0.6885 - val_loss: 0.7006\n",
            "Epoch 7/200\n",
            "50/50 - 0s - loss: 0.6673 - val_loss: 0.6886\n",
            "Epoch 8/200\n",
            "50/50 - 0s - loss: 0.6515 - val_loss: 0.6869\n",
            "Epoch 9/200\n",
            "50/50 - 0s - loss: 0.6333 - val_loss: 0.6835\n",
            "Epoch 10/200\n",
            "50/50 - 0s - loss: 0.6250 - val_loss: 0.6706\n",
            "Epoch 11/200\n",
            "50/50 - 0s - loss: 0.6137 - val_loss: 0.6680\n",
            "Epoch 12/200\n",
            "50/50 - 0s - loss: 0.6043 - val_loss: 0.6714\n",
            "Epoch 13/200\n",
            "50/50 - 0s - loss: 0.5920 - val_loss: 0.6599\n",
            "Epoch 14/200\n",
            "50/50 - 0s - loss: 0.5836 - val_loss: 0.6557\n",
            "Epoch 15/200\n",
            "50/50 - 0s - loss: 0.5719 - val_loss: 0.6574\n",
            "Epoch 16/200\n",
            "50/50 - 0s - loss: 0.5631 - val_loss: 0.6618\n",
            "Epoch 17/200\n",
            "50/50 - 0s - loss: 0.5529 - val_loss: 0.6746\n",
            "Epoch 18/200\n",
            "50/50 - 0s - loss: 0.5459 - val_loss: 0.6564\n",
            "Epoch 19/200\n",
            "50/50 - 0s - loss: 0.5411 - val_loss: 0.6537\n",
            "Epoch 20/200\n",
            "50/50 - 0s - loss: 0.5306 - val_loss: 0.6780\n",
            "Epoch 21/200\n",
            "50/50 - 0s - loss: 0.5250 - val_loss: 0.6688\n",
            "Epoch 22/200\n",
            "50/50 - 0s - loss: 0.5206 - val_loss: 0.6680\n",
            "Epoch 23/200\n",
            "50/50 - 0s - loss: 0.5126 - val_loss: 0.6542\n",
            "Epoch 24/200\n",
            "50/50 - 0s - loss: 0.5023 - val_loss: 0.6629\n",
            "Epoch 25/200\n",
            "50/50 - 0s - loss: 0.4964 - val_loss: 0.6444\n",
            "Epoch 26/200\n",
            "50/50 - 0s - loss: 0.4872 - val_loss: 0.6573\n",
            "Epoch 27/200\n",
            "50/50 - 0s - loss: 0.4807 - val_loss: 0.6458\n",
            "Epoch 28/200\n",
            "50/50 - 0s - loss: 0.4753 - val_loss: 0.6627\n",
            "Epoch 29/200\n",
            "50/50 - 0s - loss: 0.4748 - val_loss: 0.6562\n",
            "Epoch 30/200\n",
            "50/50 - 0s - loss: 0.4676 - val_loss: 0.6655\n",
            "Epoch 31/200\n",
            "50/50 - 0s - loss: 0.4639 - val_loss: 0.6548\n",
            "Epoch 32/200\n",
            "50/50 - 0s - loss: 0.4522 - val_loss: 0.6730\n",
            "Epoch 33/200\n",
            "50/50 - 0s - loss: 0.4462 - val_loss: 0.6495\n",
            "Epoch 34/200\n",
            "50/50 - 0s - loss: 0.4381 - val_loss: 0.6762\n",
            "Epoch 35/200\n",
            "50/50 - 0s - loss: 0.4369 - val_loss: 0.6670\n",
            "Epoch 36/200\n",
            "50/50 - 0s - loss: 0.4290 - val_loss: 0.6583\n",
            "Epoch 37/200\n",
            "50/50 - 0s - loss: 0.4212 - val_loss: 0.6744\n",
            "Epoch 38/200\n",
            "50/50 - 0s - loss: 0.4152 - val_loss: 0.6875\n",
            "Epoch 39/200\n",
            "50/50 - 0s - loss: 0.4115 - val_loss: 0.7020\n",
            "Epoch 40/200\n",
            "50/50 - 0s - loss: 0.4046 - val_loss: 0.6756\n",
            "Epoch 41/200\n",
            "50/50 - 0s - loss: 0.4017 - val_loss: 0.6742\n",
            "Epoch 42/200\n",
            "50/50 - 0s - loss: 0.3988 - val_loss: 0.6870\n",
            "Epoch 43/200\n",
            "50/50 - 0s - loss: 0.3903 - val_loss: 0.7088\n",
            "Epoch 44/200\n",
            "50/50 - 0s - loss: 0.3828 - val_loss: 0.7152\n",
            "Epoch 45/200\n",
            "50/50 - 0s - loss: 0.3804 - val_loss: 0.7060\n",
            "Epoch 46/200\n",
            "50/50 - 0s - loss: 0.3762 - val_loss: 0.7050\n",
            "Epoch 47/200\n",
            "50/50 - 0s - loss: 0.3691 - val_loss: 0.6983\n",
            "Epoch 48/200\n",
            "50/50 - 0s - loss: 0.3644 - val_loss: 0.7022\n",
            "Epoch 49/200\n",
            "50/50 - 0s - loss: 0.3622 - val_loss: 0.7364\n",
            "Epoch 50/200\n",
            "50/50 - 0s - loss: 0.3580 - val_loss: 0.7223\n",
            "Epoch 51/200\n",
            "50/50 - 0s - loss: 0.3520 - val_loss: 0.7273\n",
            "Epoch 52/200\n",
            "50/50 - 0s - loss: 0.3397 - val_loss: 0.7372\n",
            "Epoch 53/200\n",
            "50/50 - 0s - loss: 0.3436 - val_loss: 0.7468\n",
            "Epoch 54/200\n",
            "50/50 - 0s - loss: 0.3330 - val_loss: 0.7556\n",
            "Epoch 55/200\n",
            "50/50 - 0s - loss: 0.3334 - val_loss: 0.7507\n",
            "Epoch 56/200\n",
            "50/50 - 0s - loss: 0.3279 - val_loss: 0.7472\n",
            "Epoch 57/200\n",
            "50/50 - 0s - loss: 0.3230 - val_loss: 0.7350\n",
            "Epoch 58/200\n",
            "50/50 - 0s - loss: 0.3206 - val_loss: 0.7563\n",
            "Epoch 59/200\n",
            "50/50 - 0s - loss: 0.3138 - val_loss: 0.8028\n",
            "Epoch 60/200\n",
            "50/50 - 0s - loss: 0.3028 - val_loss: 0.7578\n",
            "Epoch 61/200\n",
            "50/50 - 0s - loss: 0.3047 - val_loss: 0.8170\n",
            "Epoch 62/200\n",
            "50/50 - 0s - loss: 0.2979 - val_loss: 0.8082\n",
            "Epoch 63/200\n",
            "50/50 - 0s - loss: 0.2971 - val_loss: 0.7714\n",
            "Epoch 64/200\n",
            "50/50 - 0s - loss: 0.2954 - val_loss: 0.7818\n",
            "Epoch 65/200\n",
            "50/50 - 0s - loss: 0.2850 - val_loss: 0.7966\n",
            "Epoch 66/200\n",
            "50/50 - 0s - loss: 0.2849 - val_loss: 0.8081\n",
            "Epoch 67/200\n",
            "50/50 - 0s - loss: 0.2729 - val_loss: 0.8081\n",
            "Epoch 68/200\n",
            "50/50 - 0s - loss: 0.2748 - val_loss: 0.8423\n",
            "Epoch 69/200\n",
            "50/50 - 0s - loss: 0.2689 - val_loss: 0.7989\n",
            "Epoch 70/200\n",
            "50/50 - 0s - loss: 0.2665 - val_loss: 0.7912\n",
            "Epoch 71/200\n",
            "50/50 - 0s - loss: 0.2561 - val_loss: 0.8364\n",
            "Epoch 72/200\n",
            "50/50 - 0s - loss: 0.2636 - val_loss: 0.8056\n",
            "Epoch 73/200\n",
            "50/50 - 0s - loss: 0.2549 - val_loss: 0.8658\n",
            "Epoch 74/200\n",
            "50/50 - 0s - loss: 0.2482 - val_loss: 0.8485\n",
            "Epoch 75/200\n",
            "50/50 - 0s - loss: 0.2428 - val_loss: 0.8535\n",
            "Epoch 76/200\n",
            "50/50 - 0s - loss: 0.2464 - val_loss: 0.8696\n",
            "Epoch 77/200\n",
            "50/50 - 0s - loss: 0.2381 - val_loss: 0.8278\n",
            "Epoch 78/200\n",
            "50/50 - 0s - loss: 0.2292 - val_loss: 0.8860\n",
            "Epoch 79/200\n",
            "50/50 - 0s - loss: 0.2286 - val_loss: 0.9499\n",
            "Epoch 80/200\n",
            "50/50 - 0s - loss: 0.2290 - val_loss: 0.9141\n",
            "Epoch 81/200\n",
            "50/50 - 0s - loss: 0.2275 - val_loss: 0.8829\n",
            "Epoch 82/200\n",
            "50/50 - 0s - loss: 0.2205 - val_loss: 0.9016\n",
            "Epoch 83/200\n",
            "50/50 - 0s - loss: 0.2187 - val_loss: 0.8598\n",
            "Epoch 84/200\n",
            "50/50 - 0s - loss: 0.2110 - val_loss: 0.9000\n",
            "Epoch 85/200\n",
            "50/50 - 0s - loss: 0.2133 - val_loss: 0.9157\n",
            "Epoch 86/200\n",
            "50/50 - 0s - loss: 0.2036 - val_loss: 0.9187\n",
            "Epoch 87/200\n",
            "50/50 - 0s - loss: 0.2078 - val_loss: 0.9122\n",
            "Epoch 88/200\n",
            "50/50 - 0s - loss: 0.1951 - val_loss: 0.9532\n",
            "Epoch 89/200\n",
            "50/50 - 0s - loss: 0.2011 - val_loss: 0.9401\n",
            "Epoch 90/200\n",
            "50/50 - 0s - loss: 0.1906 - val_loss: 0.9796\n",
            "Epoch 91/200\n",
            "50/50 - 0s - loss: 0.1914 - val_loss: 0.9828\n",
            "Epoch 92/200\n",
            "50/50 - 0s - loss: 0.1866 - val_loss: 0.9400\n",
            "Epoch 93/200\n",
            "50/50 - 0s - loss: 0.1878 - val_loss: 0.9390\n",
            "Epoch 94/200\n",
            "50/50 - 0s - loss: 0.1737 - val_loss: 0.9928\n",
            "Epoch 95/200\n",
            "50/50 - 0s - loss: 0.1781 - val_loss: 0.9332\n",
            "Epoch 96/200\n",
            "50/50 - 0s - loss: 0.1759 - val_loss: 1.0310\n",
            "Epoch 97/200\n",
            "50/50 - 0s - loss: 0.1779 - val_loss: 0.9941\n",
            "Epoch 98/200\n",
            "50/50 - 0s - loss: 0.1705 - val_loss: 1.0726\n",
            "Epoch 99/200\n",
            "50/50 - 0s - loss: 0.1652 - val_loss: 1.0020\n",
            "Epoch 100/200\n",
            "50/50 - 0s - loss: 0.1673 - val_loss: 1.0377\n",
            "Epoch 101/200\n",
            "50/50 - 0s - loss: 0.1631 - val_loss: 1.0045\n",
            "Epoch 102/200\n",
            "50/50 - 0s - loss: 0.1609 - val_loss: 1.0385\n",
            "Epoch 103/200\n",
            "50/50 - 0s - loss: 0.1546 - val_loss: 1.1053\n",
            "Epoch 104/200\n",
            "50/50 - 0s - loss: 0.1577 - val_loss: 1.0634\n",
            "Epoch 105/200\n",
            "50/50 - 0s - loss: 0.1501 - val_loss: 1.0793\n",
            "Epoch 106/200\n",
            "50/50 - 0s - loss: 0.1570 - val_loss: 1.0578\n",
            "Epoch 107/200\n",
            "50/50 - 0s - loss: 0.1527 - val_loss: 1.0528\n",
            "Epoch 108/200\n",
            "50/50 - 0s - loss: 0.1423 - val_loss: 1.0988\n",
            "Epoch 109/200\n",
            "50/50 - 0s - loss: 0.1415 - val_loss: 1.1349\n",
            "Epoch 110/200\n",
            "50/50 - 0s - loss: 0.1464 - val_loss: 1.1358\n",
            "Epoch 111/200\n",
            "50/50 - 0s - loss: 0.1425 - val_loss: 1.1004\n",
            "Epoch 112/200\n",
            "50/50 - 0s - loss: 0.1369 - val_loss: 1.1621\n",
            "Epoch 113/200\n",
            "50/50 - 0s - loss: 0.1384 - val_loss: 1.1226\n",
            "Epoch 114/200\n",
            "50/50 - 0s - loss: 0.1285 - val_loss: 1.1113\n",
            "Epoch 115/200\n",
            "50/50 - 0s - loss: 0.1329 - val_loss: 1.1253\n",
            "Epoch 116/200\n",
            "50/50 - 0s - loss: 0.1320 - val_loss: 1.2301\n",
            "Epoch 117/200\n",
            "50/50 - 0s - loss: 0.1341 - val_loss: 1.1486\n",
            "Epoch 118/200\n",
            "50/50 - 0s - loss: 0.1268 - val_loss: 1.2032\n",
            "Epoch 119/200\n",
            "50/50 - 0s - loss: 0.1331 - val_loss: 1.0978\n",
            "Epoch 120/200\n",
            "50/50 - 0s - loss: 0.1242 - val_loss: 1.1402\n",
            "Epoch 121/200\n",
            "50/50 - 0s - loss: 0.1156 - val_loss: 1.1910\n",
            "Epoch 122/200\n",
            "50/50 - 0s - loss: 0.1194 - val_loss: 1.2007\n",
            "Epoch 123/200\n",
            "50/50 - 0s - loss: 0.1211 - val_loss: 1.2337\n",
            "Epoch 124/200\n",
            "50/50 - 0s - loss: 0.1139 - val_loss: 1.2130\n",
            "Epoch 125/200\n",
            "50/50 - 0s - loss: 0.1061 - val_loss: 1.2095\n",
            "Epoch 126/200\n",
            "50/50 - 0s - loss: 0.1211 - val_loss: 1.2184\n",
            "Epoch 127/200\n",
            "50/50 - 0s - loss: 0.1128 - val_loss: 1.2296\n",
            "Epoch 128/200\n",
            "50/50 - 0s - loss: 0.1122 - val_loss: 1.2795\n",
            "Epoch 129/200\n",
            "50/50 - 0s - loss: 0.1102 - val_loss: 1.2588\n",
            "Epoch 130/200\n",
            "50/50 - 0s - loss: 0.1017 - val_loss: 1.2465\n",
            "Epoch 131/200\n",
            "50/50 - 0s - loss: 0.1100 - val_loss: 1.2523\n",
            "Epoch 132/200\n",
            "50/50 - 0s - loss: 0.1017 - val_loss: 1.2866\n",
            "Epoch 133/200\n",
            "50/50 - 0s - loss: 0.1007 - val_loss: 1.2270\n",
            "Epoch 134/200\n",
            "50/50 - 0s - loss: 0.1037 - val_loss: 1.2478\n",
            "Epoch 135/200\n",
            "50/50 - 0s - loss: 0.0993 - val_loss: 1.2330\n",
            "Epoch 136/200\n",
            "50/50 - 0s - loss: 0.0973 - val_loss: 1.3117\n",
            "Epoch 137/200\n",
            "50/50 - 0s - loss: 0.0952 - val_loss: 1.3361\n",
            "Epoch 138/200\n",
            "50/50 - 0s - loss: 0.0966 - val_loss: 1.2964\n",
            "Epoch 139/200\n",
            "50/50 - 0s - loss: 0.0923 - val_loss: 1.2672\n",
            "Epoch 140/200\n",
            "50/50 - 0s - loss: 0.0925 - val_loss: 1.3343\n",
            "Epoch 141/200\n",
            "50/50 - 0s - loss: 0.0948 - val_loss: 1.3323\n",
            "Epoch 142/200\n",
            "50/50 - 0s - loss: 0.0921 - val_loss: 1.4901\n",
            "Epoch 143/200\n",
            "50/50 - 0s - loss: 0.0907 - val_loss: 1.3215\n",
            "Epoch 144/200\n",
            "50/50 - 0s - loss: 0.0886 - val_loss: 1.3874\n",
            "Epoch 145/200\n",
            "50/50 - 0s - loss: 0.0850 - val_loss: 1.3841\n",
            "Epoch 146/200\n",
            "50/50 - 0s - loss: 0.0851 - val_loss: 1.3730\n",
            "Epoch 147/200\n",
            "50/50 - 0s - loss: 0.0791 - val_loss: 1.3540\n",
            "Epoch 148/200\n",
            "50/50 - 0s - loss: 0.0861 - val_loss: 1.3889\n",
            "Epoch 149/200\n",
            "50/50 - 0s - loss: 0.0828 - val_loss: 1.5641\n",
            "Epoch 150/200\n",
            "50/50 - 0s - loss: 0.0848 - val_loss: 1.4223\n",
            "Epoch 151/200\n",
            "50/50 - 0s - loss: 0.0811 - val_loss: 1.4614\n",
            "Epoch 152/200\n",
            "50/50 - 0s - loss: 0.0763 - val_loss: 1.4140\n",
            "Epoch 153/200\n",
            "50/50 - 0s - loss: 0.0813 - val_loss: 1.6794\n",
            "Epoch 154/200\n",
            "50/50 - 0s - loss: 0.0801 - val_loss: 1.4317\n",
            "Epoch 155/200\n",
            "50/50 - 0s - loss: 0.0719 - val_loss: 1.4374\n",
            "Epoch 156/200\n",
            "50/50 - 0s - loss: 0.0807 - val_loss: 1.4979\n",
            "Epoch 157/200\n",
            "50/50 - 0s - loss: 0.0771 - val_loss: 1.4695\n",
            "Epoch 158/200\n",
            "50/50 - 0s - loss: 0.0709 - val_loss: 1.5229\n",
            "Epoch 159/200\n",
            "50/50 - 0s - loss: 0.0679 - val_loss: 1.4794\n",
            "Epoch 160/200\n",
            "50/50 - 0s - loss: 0.0800 - val_loss: 1.4498\n",
            "Epoch 161/200\n",
            "50/50 - 0s - loss: 0.0713 - val_loss: 1.5370\n",
            "Epoch 162/200\n",
            "50/50 - 0s - loss: 0.0642 - val_loss: 1.5452\n",
            "Epoch 163/200\n",
            "50/50 - 0s - loss: 0.0619 - val_loss: 1.5374\n",
            "Epoch 164/200\n",
            "50/50 - 0s - loss: 0.0675 - val_loss: 1.5267\n",
            "Epoch 165/200\n",
            "50/50 - 0s - loss: 0.0646 - val_loss: 1.5109\n",
            "Epoch 166/200\n",
            "50/50 - 0s - loss: 0.0720 - val_loss: 1.5494\n",
            "Epoch 167/200\n",
            "50/50 - 0s - loss: 0.0624 - val_loss: 1.6075\n",
            "Epoch 168/200\n",
            "50/50 - 0s - loss: 0.0585 - val_loss: 1.6556\n",
            "Epoch 169/200\n",
            "50/50 - 0s - loss: 0.0662 - val_loss: 1.5742\n",
            "Epoch 170/200\n",
            "50/50 - 0s - loss: 0.0599 - val_loss: 1.5568\n",
            "Epoch 171/200\n",
            "50/50 - 0s - loss: 0.0648 - val_loss: 1.6068\n",
            "Epoch 172/200\n",
            "50/50 - 0s - loss: 0.0606 - val_loss: 1.5573\n",
            "Epoch 173/200\n",
            "50/50 - 0s - loss: 0.0603 - val_loss: 1.6056\n",
            "Epoch 174/200\n",
            "50/50 - 0s - loss: 0.0625 - val_loss: 1.6572\n",
            "Epoch 175/200\n",
            "50/50 - 0s - loss: 0.0587 - val_loss: 1.6478\n",
            "Epoch 176/200\n",
            "50/50 - 0s - loss: 0.0526 - val_loss: 1.6292\n",
            "Epoch 177/200\n",
            "50/50 - 0s - loss: 0.0558 - val_loss: 1.5829\n",
            "Epoch 178/200\n",
            "50/50 - 0s - loss: 0.0631 - val_loss: 1.7101\n",
            "Epoch 179/200\n",
            "50/50 - 0s - loss: 0.0573 - val_loss: 1.7146\n",
            "Epoch 180/200\n",
            "50/50 - 0s - loss: 0.0541 - val_loss: 1.6632\n",
            "Epoch 181/200\n",
            "50/50 - 0s - loss: 0.0494 - val_loss: 1.7010\n",
            "Epoch 182/200\n",
            "50/50 - 0s - loss: 0.0550 - val_loss: 1.7294\n",
            "Epoch 183/200\n",
            "50/50 - 0s - loss: 0.0583 - val_loss: 1.6819\n",
            "Epoch 184/200\n",
            "50/50 - 0s - loss: 0.0516 - val_loss: 1.7772\n",
            "Epoch 185/200\n",
            "50/50 - 0s - loss: 0.0457 - val_loss: 1.7855\n",
            "Epoch 186/200\n",
            "50/50 - 0s - loss: 0.0518 - val_loss: 1.6935\n",
            "Epoch 187/200\n",
            "50/50 - 0s - loss: 0.0532 - val_loss: 1.7973\n",
            "Epoch 188/200\n",
            "50/50 - 0s - loss: 0.0535 - val_loss: 1.7490\n",
            "Epoch 189/200\n",
            "50/50 - 0s - loss: 0.0467 - val_loss: 1.7878\n",
            "Epoch 190/200\n",
            "50/50 - 0s - loss: 0.0555 - val_loss: 1.7967\n",
            "Epoch 191/200\n",
            "50/50 - 0s - loss: 0.0442 - val_loss: 1.7897\n",
            "Epoch 192/200\n",
            "50/50 - 0s - loss: 0.0517 - val_loss: 1.7937\n",
            "Epoch 193/200\n",
            "50/50 - 0s - loss: 0.0411 - val_loss: 1.8413\n",
            "Epoch 194/200\n",
            "50/50 - 0s - loss: 0.0455 - val_loss: 1.8347\n",
            "Epoch 195/200\n",
            "50/50 - 0s - loss: 0.0476 - val_loss: 1.8686\n",
            "Epoch 196/200\n",
            "50/50 - 0s - loss: 0.0476 - val_loss: 1.7942\n",
            "Epoch 197/200\n",
            "50/50 - 0s - loss: 0.0458 - val_loss: 1.8372\n",
            "Epoch 198/200\n",
            "50/50 - 0s - loss: 0.0424 - val_loss: 1.8767\n",
            "Epoch 199/200\n",
            "50/50 - 0s - loss: 0.0416 - val_loss: 1.8526\n",
            "Epoch 200/200\n",
            "50/50 - 0s - loss: 0.0451 - val_loss: 1.8502\n",
            "the accuracy at fold: 2 is: 0.7125\n",
            "fold number: 5\n",
            "Epoch 1/200\n",
            "50/50 - 1s - loss: 1.2070 - val_loss: 0.9285\n",
            "Epoch 2/200\n",
            "50/50 - 0s - loss: 0.8549 - val_loss: 0.8143\n",
            "Epoch 3/200\n",
            "50/50 - 0s - loss: 0.7712 - val_loss: 0.7796\n",
            "Epoch 4/200\n",
            "50/50 - 0s - loss: 0.7244 - val_loss: 0.7491\n",
            "Epoch 5/200\n",
            "50/50 - 0s - loss: 0.6933 - val_loss: 0.7404\n",
            "Epoch 6/200\n",
            "50/50 - 0s - loss: 0.6686 - val_loss: 0.7244\n",
            "Epoch 7/200\n",
            "50/50 - 0s - loss: 0.6475 - val_loss: 0.7292\n",
            "Epoch 8/200\n",
            "50/50 - 0s - loss: 0.6301 - val_loss: 0.7261\n",
            "Epoch 9/200\n",
            "50/50 - 0s - loss: 0.6163 - val_loss: 0.7183\n",
            "Epoch 10/200\n",
            "50/50 - 0s - loss: 0.6038 - val_loss: 0.7260\n",
            "Epoch 11/200\n",
            "50/50 - 0s - loss: 0.5888 - val_loss: 0.7074\n",
            "Epoch 12/200\n",
            "50/50 - 0s - loss: 0.5835 - val_loss: 0.7212\n",
            "Epoch 13/200\n",
            "50/50 - 0s - loss: 0.5690 - val_loss: 0.7031\n",
            "Epoch 14/200\n",
            "50/50 - 0s - loss: 0.5583 - val_loss: 0.7229\n",
            "Epoch 15/200\n",
            "50/50 - 0s - loss: 0.5512 - val_loss: 0.7325\n",
            "Epoch 16/200\n",
            "50/50 - 0s - loss: 0.5383 - val_loss: 0.7152\n",
            "Epoch 17/200\n",
            "50/50 - 0s - loss: 0.5272 - val_loss: 0.7154\n",
            "Epoch 18/200\n",
            "50/50 - 0s - loss: 0.5166 - val_loss: 0.7403\n",
            "Epoch 19/200\n",
            "50/50 - 0s - loss: 0.5129 - val_loss: 0.7249\n",
            "Epoch 20/200\n",
            "50/50 - 0s - loss: 0.5037 - val_loss: 0.7266\n",
            "Epoch 21/200\n",
            "50/50 - 0s - loss: 0.4912 - val_loss: 0.7493\n",
            "Epoch 22/200\n",
            "50/50 - 0s - loss: 0.4810 - val_loss: 0.7411\n",
            "Epoch 23/200\n",
            "50/50 - 0s - loss: 0.4792 - val_loss: 0.7292\n",
            "Epoch 24/200\n",
            "50/50 - 0s - loss: 0.4689 - val_loss: 0.7407\n",
            "Epoch 25/200\n",
            "50/50 - 0s - loss: 0.4671 - val_loss: 0.7391\n",
            "Epoch 26/200\n",
            "50/50 - 0s - loss: 0.4558 - val_loss: 0.7517\n",
            "Epoch 27/200\n",
            "50/50 - 0s - loss: 0.4491 - val_loss: 0.7615\n",
            "Epoch 28/200\n",
            "50/50 - 0s - loss: 0.4405 - val_loss: 0.7623\n",
            "Epoch 29/200\n",
            "50/50 - 0s - loss: 0.4362 - val_loss: 0.7696\n",
            "Epoch 30/200\n",
            "50/50 - 0s - loss: 0.4303 - val_loss: 0.7746\n",
            "Epoch 31/200\n",
            "50/50 - 0s - loss: 0.4205 - val_loss: 0.7754\n",
            "Epoch 32/200\n",
            "50/50 - 0s - loss: 0.4224 - val_loss: 0.7783\n",
            "Epoch 33/200\n",
            "50/50 - 0s - loss: 0.4147 - val_loss: 0.7953\n",
            "Epoch 34/200\n",
            "50/50 - 0s - loss: 0.4069 - val_loss: 0.7878\n",
            "Epoch 35/200\n",
            "50/50 - 0s - loss: 0.4002 - val_loss: 0.8055\n",
            "Epoch 36/200\n",
            "50/50 - 0s - loss: 0.3981 - val_loss: 0.8003\n",
            "Epoch 37/200\n",
            "50/50 - 0s - loss: 0.3903 - val_loss: 0.8140\n",
            "Epoch 38/200\n",
            "50/50 - 0s - loss: 0.3829 - val_loss: 0.8213\n",
            "Epoch 39/200\n",
            "50/50 - 0s - loss: 0.3769 - val_loss: 0.8163\n",
            "Epoch 40/200\n",
            "50/50 - 0s - loss: 0.3765 - val_loss: 0.8262\n",
            "Epoch 41/200\n",
            "50/50 - 0s - loss: 0.3708 - val_loss: 0.8330\n",
            "Epoch 42/200\n",
            "50/50 - 0s - loss: 0.3622 - val_loss: 0.8594\n",
            "Epoch 43/200\n",
            "50/50 - 0s - loss: 0.3571 - val_loss: 0.8451\n",
            "Epoch 44/200\n",
            "50/50 - 0s - loss: 0.3507 - val_loss: 0.8585\n",
            "Epoch 45/200\n",
            "50/50 - 0s - loss: 0.3527 - val_loss: 0.8908\n",
            "Epoch 46/200\n",
            "50/50 - 0s - loss: 0.3457 - val_loss: 0.8629\n",
            "Epoch 47/200\n",
            "50/50 - 0s - loss: 0.3390 - val_loss: 0.8862\n",
            "Epoch 48/200\n",
            "50/50 - 0s - loss: 0.3363 - val_loss: 0.8954\n",
            "Epoch 49/200\n",
            "50/50 - 0s - loss: 0.3296 - val_loss: 0.9027\n",
            "Epoch 50/200\n",
            "50/50 - 0s - loss: 0.3219 - val_loss: 0.9162\n",
            "Epoch 51/200\n",
            "50/50 - 0s - loss: 0.3246 - val_loss: 0.9081\n",
            "Epoch 52/200\n",
            "50/50 - 0s - loss: 0.3155 - val_loss: 0.9244\n",
            "Epoch 53/200\n",
            "50/50 - 0s - loss: 0.3128 - val_loss: 0.9489\n",
            "Epoch 54/200\n",
            "50/50 - 0s - loss: 0.3050 - val_loss: 0.9419\n",
            "Epoch 55/200\n",
            "50/50 - 0s - loss: 0.2970 - val_loss: 0.9854\n",
            "Epoch 56/200\n",
            "50/50 - 0s - loss: 0.3038 - val_loss: 0.9506\n",
            "Epoch 57/200\n",
            "50/50 - 0s - loss: 0.2957 - val_loss: 0.9219\n",
            "Epoch 58/200\n",
            "50/50 - 0s - loss: 0.2943 - val_loss: 0.9740\n",
            "Epoch 59/200\n",
            "50/50 - 0s - loss: 0.2921 - val_loss: 0.9842\n",
            "Epoch 60/200\n",
            "50/50 - 0s - loss: 0.2849 - val_loss: 0.9890\n",
            "Epoch 61/200\n",
            "50/50 - 0s - loss: 0.2841 - val_loss: 1.0149\n",
            "Epoch 62/200\n",
            "50/50 - 0s - loss: 0.2764 - val_loss: 1.0576\n",
            "Epoch 63/200\n",
            "50/50 - 0s - loss: 0.2780 - val_loss: 1.0317\n",
            "Epoch 64/200\n",
            "50/50 - 0s - loss: 0.2723 - val_loss: 1.0255\n",
            "Epoch 65/200\n",
            "50/50 - 0s - loss: 0.2685 - val_loss: 1.0446\n",
            "Epoch 66/200\n",
            "50/50 - 0s - loss: 0.2644 - val_loss: 1.0385\n",
            "Epoch 67/200\n",
            "50/50 - 0s - loss: 0.2552 - val_loss: 1.0533\n",
            "Epoch 68/200\n",
            "50/50 - 0s - loss: 0.2556 - val_loss: 1.0597\n",
            "Epoch 69/200\n",
            "50/50 - 0s - loss: 0.2569 - val_loss: 1.1050\n",
            "Epoch 70/200\n",
            "50/50 - 0s - loss: 0.2494 - val_loss: 1.0853\n",
            "Epoch 71/200\n",
            "50/50 - 0s - loss: 0.2454 - val_loss: 1.0865\n",
            "Epoch 72/200\n",
            "50/50 - 0s - loss: 0.2392 - val_loss: 1.0822\n",
            "Epoch 73/200\n",
            "50/50 - 0s - loss: 0.2406 - val_loss: 1.0778\n",
            "Epoch 74/200\n",
            "50/50 - 0s - loss: 0.2382 - val_loss: 1.1020\n",
            "Epoch 75/200\n",
            "50/50 - 0s - loss: 0.2330 - val_loss: 1.1125\n",
            "Epoch 76/200\n",
            "50/50 - 0s - loss: 0.2342 - val_loss: 1.1944\n",
            "Epoch 77/200\n",
            "50/50 - 0s - loss: 0.2307 - val_loss: 1.1309\n",
            "Epoch 78/200\n",
            "50/50 - 0s - loss: 0.2247 - val_loss: 1.1778\n",
            "Epoch 79/200\n",
            "50/50 - 0s - loss: 0.2261 - val_loss: 1.1778\n",
            "Epoch 80/200\n",
            "50/50 - 0s - loss: 0.2150 - val_loss: 1.1427\n",
            "Epoch 81/200\n",
            "50/50 - 0s - loss: 0.2167 - val_loss: 1.1546\n",
            "Epoch 82/200\n",
            "50/50 - 0s - loss: 0.2107 - val_loss: 1.2044\n",
            "Epoch 83/200\n",
            "50/50 - 0s - loss: 0.2129 - val_loss: 1.1757\n",
            "Epoch 84/200\n",
            "50/50 - 0s - loss: 0.2093 - val_loss: 1.2256\n",
            "Epoch 85/200\n",
            "50/50 - 0s - loss: 0.2069 - val_loss: 1.1894\n",
            "Epoch 86/200\n",
            "50/50 - 0s - loss: 0.2005 - val_loss: 1.2715\n",
            "Epoch 87/200\n",
            "50/50 - 0s - loss: 0.2044 - val_loss: 1.2149\n",
            "Epoch 88/200\n",
            "50/50 - 0s - loss: 0.1952 - val_loss: 1.2676\n",
            "Epoch 89/200\n",
            "50/50 - 0s - loss: 0.2001 - val_loss: 1.2649\n",
            "Epoch 90/200\n",
            "50/50 - 0s - loss: 0.1945 - val_loss: 1.2981\n",
            "Epoch 91/200\n",
            "50/50 - 0s - loss: 0.1876 - val_loss: 1.3490\n",
            "Epoch 92/200\n",
            "50/50 - 0s - loss: 0.1894 - val_loss: 1.3043\n",
            "Epoch 93/200\n",
            "50/50 - 0s - loss: 0.1810 - val_loss: 1.3400\n",
            "Epoch 94/200\n",
            "50/50 - 0s - loss: 0.1853 - val_loss: 1.2830\n",
            "Epoch 95/200\n",
            "50/50 - 0s - loss: 0.1785 - val_loss: 1.3430\n",
            "Epoch 96/200\n",
            "50/50 - 0s - loss: 0.1846 - val_loss: 1.3452\n",
            "Epoch 97/200\n",
            "50/50 - 0s - loss: 0.1728 - val_loss: 1.3596\n",
            "Epoch 98/200\n",
            "50/50 - 0s - loss: 0.1713 - val_loss: 1.4064\n",
            "Epoch 99/200\n",
            "50/50 - 0s - loss: 0.1751 - val_loss: 1.3431\n",
            "Epoch 100/200\n",
            "50/50 - 0s - loss: 0.1637 - val_loss: 1.4183\n",
            "Epoch 101/200\n",
            "50/50 - 0s - loss: 0.1679 - val_loss: 1.3404\n",
            "Epoch 102/200\n",
            "50/50 - 0s - loss: 0.1649 - val_loss: 1.3661\n",
            "Epoch 103/200\n",
            "50/50 - 0s - loss: 0.1742 - val_loss: 1.3640\n",
            "Epoch 104/200\n",
            "50/50 - 0s - loss: 0.1579 - val_loss: 1.3663\n",
            "Epoch 105/200\n",
            "50/50 - 0s - loss: 0.1548 - val_loss: 1.3990\n",
            "Epoch 106/200\n",
            "50/50 - 0s - loss: 0.1609 - val_loss: 1.4216\n",
            "Epoch 107/200\n",
            "50/50 - 0s - loss: 0.1567 - val_loss: 1.4392\n",
            "Epoch 108/200\n",
            "50/50 - 0s - loss: 0.1487 - val_loss: 1.4410\n",
            "Epoch 109/200\n",
            "50/50 - 0s - loss: 0.1430 - val_loss: 1.4592\n",
            "Epoch 110/200\n",
            "50/50 - 0s - loss: 0.1477 - val_loss: 1.4457\n",
            "Epoch 111/200\n",
            "50/50 - 0s - loss: 0.1514 - val_loss: 1.4600\n",
            "Epoch 112/200\n",
            "50/50 - 0s - loss: 0.1481 - val_loss: 1.4675\n",
            "Epoch 113/200\n",
            "50/50 - 0s - loss: 0.1424 - val_loss: 1.5256\n",
            "Epoch 114/200\n",
            "50/50 - 0s - loss: 0.1453 - val_loss: 1.5601\n",
            "Epoch 115/200\n",
            "50/50 - 0s - loss: 0.1393 - val_loss: 1.5061\n",
            "Epoch 116/200\n",
            "50/50 - 0s - loss: 0.1334 - val_loss: 1.5946\n",
            "Epoch 117/200\n",
            "50/50 - 0s - loss: 0.1334 - val_loss: 1.5884\n",
            "Epoch 118/200\n",
            "50/50 - 0s - loss: 0.1274 - val_loss: 1.5320\n",
            "Epoch 119/200\n",
            "50/50 - 0s - loss: 0.1276 - val_loss: 1.6062\n",
            "Epoch 120/200\n",
            "50/50 - 0s - loss: 0.1250 - val_loss: 1.6348\n",
            "Epoch 121/200\n",
            "50/50 - 0s - loss: 0.1284 - val_loss: 1.6701\n",
            "Epoch 122/200\n",
            "50/50 - 0s - loss: 0.1293 - val_loss: 1.6165\n",
            "Epoch 123/200\n",
            "50/50 - 0s - loss: 0.1197 - val_loss: 1.6552\n",
            "Epoch 124/200\n",
            "50/50 - 0s - loss: 0.1151 - val_loss: 1.7309\n",
            "Epoch 125/200\n",
            "50/50 - 0s - loss: 0.1308 - val_loss: 1.7152\n",
            "Epoch 126/200\n",
            "50/50 - 0s - loss: 0.1144 - val_loss: 1.6666\n",
            "Epoch 127/200\n",
            "50/50 - 0s - loss: 0.1217 - val_loss: 1.8627\n",
            "Epoch 128/200\n",
            "50/50 - 0s - loss: 0.1154 - val_loss: 1.8087\n",
            "Epoch 129/200\n",
            "50/50 - 0s - loss: 0.1171 - val_loss: 1.6736\n",
            "Epoch 130/200\n",
            "50/50 - 0s - loss: 0.1161 - val_loss: 1.7692\n",
            "Epoch 131/200\n",
            "50/50 - 0s - loss: 0.1095 - val_loss: 1.7390\n",
            "Epoch 132/200\n",
            "50/50 - 0s - loss: 0.1132 - val_loss: 1.7772\n",
            "Epoch 133/200\n",
            "50/50 - 0s - loss: 0.1190 - val_loss: 1.8572\n",
            "Epoch 134/200\n",
            "50/50 - 0s - loss: 0.1126 - val_loss: 1.7307\n",
            "Epoch 135/200\n",
            "50/50 - 0s - loss: 0.1036 - val_loss: 1.7487\n",
            "Epoch 136/200\n",
            "50/50 - 0s - loss: 0.1127 - val_loss: 1.7585\n",
            "Epoch 137/200\n",
            "50/50 - 0s - loss: 0.1006 - val_loss: 1.8056\n",
            "Epoch 138/200\n",
            "50/50 - 0s - loss: 0.1116 - val_loss: 1.7730\n",
            "Epoch 139/200\n",
            "50/50 - 0s - loss: 0.1092 - val_loss: 1.8204\n",
            "Epoch 140/200\n",
            "50/50 - 0s - loss: 0.1014 - val_loss: 1.8127\n",
            "Epoch 141/200\n",
            "50/50 - 0s - loss: 0.0954 - val_loss: 1.7666\n",
            "Epoch 142/200\n",
            "50/50 - 0s - loss: 0.1004 - val_loss: 1.8657\n",
            "Epoch 143/200\n",
            "50/50 - 0s - loss: 0.0984 - val_loss: 1.8443\n",
            "Epoch 144/200\n",
            "50/50 - 0s - loss: 0.0942 - val_loss: 1.8797\n",
            "Epoch 145/200\n",
            "50/50 - 0s - loss: 0.0999 - val_loss: 1.8599\n",
            "Epoch 146/200\n",
            "50/50 - 0s - loss: 0.0907 - val_loss: 1.8901\n",
            "Epoch 147/200\n",
            "50/50 - 0s - loss: 0.0979 - val_loss: 1.8954\n",
            "Epoch 148/200\n",
            "50/50 - 0s - loss: 0.0891 - val_loss: 1.9294\n",
            "Epoch 149/200\n",
            "50/50 - 0s - loss: 0.0916 - val_loss: 1.9492\n",
            "Epoch 150/200\n",
            "50/50 - 0s - loss: 0.0909 - val_loss: 1.9435\n",
            "Epoch 151/200\n",
            "50/50 - 0s - loss: 0.0937 - val_loss: 1.9635\n",
            "Epoch 152/200\n",
            "50/50 - 0s - loss: 0.0879 - val_loss: 1.9150\n",
            "Epoch 153/200\n",
            "50/50 - 0s - loss: 0.0870 - val_loss: 1.9875\n",
            "Epoch 154/200\n",
            "50/50 - 0s - loss: 0.0831 - val_loss: 1.9348\n",
            "Epoch 155/200\n",
            "50/50 - 0s - loss: 0.0845 - val_loss: 1.9469\n",
            "Epoch 156/200\n",
            "50/50 - 0s - loss: 0.0867 - val_loss: 1.9838\n",
            "Epoch 157/200\n",
            "50/50 - 0s - loss: 0.0852 - val_loss: 1.9883\n",
            "Epoch 158/200\n",
            "50/50 - 0s - loss: 0.0767 - val_loss: 1.9945\n",
            "Epoch 159/200\n",
            "50/50 - 0s - loss: 0.0851 - val_loss: 2.0059\n",
            "Epoch 160/200\n",
            "50/50 - 0s - loss: 0.0787 - val_loss: 2.0492\n",
            "Epoch 161/200\n",
            "50/50 - 0s - loss: 0.0755 - val_loss: 2.0552\n",
            "Epoch 162/200\n",
            "50/50 - 0s - loss: 0.0796 - val_loss: 2.0398\n",
            "Epoch 163/200\n",
            "50/50 - 0s - loss: 0.0746 - val_loss: 2.1688\n",
            "Epoch 164/200\n",
            "50/50 - 0s - loss: 0.0813 - val_loss: 2.0715\n",
            "Epoch 165/200\n",
            "50/50 - 0s - loss: 0.0700 - val_loss: 2.1455\n",
            "Epoch 166/200\n",
            "50/50 - 0s - loss: 0.0736 - val_loss: 2.0709\n",
            "Epoch 167/200\n",
            "50/50 - 0s - loss: 0.0705 - val_loss: 2.1035\n",
            "Epoch 168/200\n",
            "50/50 - 0s - loss: 0.0702 - val_loss: 2.0712\n",
            "Epoch 169/200\n",
            "50/50 - 0s - loss: 0.0728 - val_loss: 2.0860\n",
            "Epoch 170/200\n",
            "50/50 - 0s - loss: 0.0686 - val_loss: 2.1986\n",
            "Epoch 171/200\n",
            "50/50 - 0s - loss: 0.0741 - val_loss: 2.1481\n",
            "Epoch 172/200\n",
            "50/50 - 0s - loss: 0.0710 - val_loss: 2.1529\n",
            "Epoch 173/200\n",
            "50/50 - 0s - loss: 0.0698 - val_loss: 2.1368\n",
            "Epoch 174/200\n",
            "50/50 - 0s - loss: 0.0679 - val_loss: 2.2366\n",
            "Epoch 175/200\n",
            "50/50 - 0s - loss: 0.0636 - val_loss: 2.2269\n",
            "Epoch 176/200\n",
            "50/50 - 0s - loss: 0.0747 - val_loss: 2.2210\n",
            "Epoch 177/200\n",
            "50/50 - 0s - loss: 0.0639 - val_loss: 2.2835\n",
            "Epoch 178/200\n",
            "50/50 - 0s - loss: 0.0554 - val_loss: 2.2391\n",
            "Epoch 179/200\n",
            "50/50 - 0s - loss: 0.0591 - val_loss: 2.2809\n",
            "Epoch 180/200\n",
            "50/50 - 0s - loss: 0.0708 - val_loss: 2.2621\n",
            "Epoch 181/200\n",
            "50/50 - 0s - loss: 0.0521 - val_loss: 2.4165\n",
            "Epoch 182/200\n",
            "50/50 - 0s - loss: 0.0661 - val_loss: 2.1968\n",
            "Epoch 183/200\n",
            "50/50 - 0s - loss: 0.0599 - val_loss: 2.2648\n",
            "Epoch 184/200\n",
            "50/50 - 0s - loss: 0.0630 - val_loss: 2.2602\n",
            "Epoch 185/200\n",
            "50/50 - 0s - loss: 0.0658 - val_loss: 2.2733\n",
            "Epoch 186/200\n",
            "50/50 - 0s - loss: 0.0676 - val_loss: 2.2584\n",
            "Epoch 187/200\n",
            "50/50 - 0s - loss: 0.0559 - val_loss: 2.3331\n",
            "Epoch 188/200\n",
            "50/50 - 0s - loss: 0.0579 - val_loss: 2.3161\n",
            "Epoch 189/200\n",
            "50/50 - 0s - loss: 0.0650 - val_loss: 2.5092\n",
            "Epoch 190/200\n",
            "50/50 - 0s - loss: 0.0599 - val_loss: 2.4356\n",
            "Epoch 191/200\n",
            "50/50 - 0s - loss: 0.0597 - val_loss: 2.3582\n",
            "Epoch 192/200\n",
            "50/50 - 0s - loss: 0.0514 - val_loss: 2.3474\n",
            "Epoch 193/200\n",
            "50/50 - 0s - loss: 0.0553 - val_loss: 2.3834\n",
            "Epoch 194/200\n",
            "50/50 - 0s - loss: 0.0542 - val_loss: 2.3757\n",
            "Epoch 195/200\n",
            "50/50 - 0s - loss: 0.0521 - val_loss: 2.5316\n",
            "Epoch 196/200\n",
            "50/50 - 0s - loss: 0.0587 - val_loss: 2.4086\n",
            "Epoch 197/200\n",
            "50/50 - 0s - loss: 0.0472 - val_loss: 2.3492\n",
            "Epoch 198/200\n",
            "50/50 - 0s - loss: 0.0530 - val_loss: 2.5171\n",
            "Epoch 199/200\n",
            "50/50 - 0s - loss: 0.0587 - val_loss: 2.4479\n",
            "Epoch 200/200\n",
            "50/50 - 0s - loss: 0.0518 - val_loss: 2.3920\n",
            "the accuracy at fold: 2 is: 0.6800\n",
            "overall accuracy 0.6900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sks0eoATBJY6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}